{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT0DPPWDJGxmEQrSCC4OHu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiarccorrea/case-ticketsclassification/blob/main/case_ticketclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Objetivo de negócio: acelerar a distribuição (triagem) de tickets para o time correto, reduzindo tempo de fila e retrabalho.**\n",
        "\n",
        "**Contexto dos chamados: dataset é composto de tickets de suporte de TI corporativo, com foco em infraestrutura, hardware, rede e software.**\n",
        "\n",
        "A partir do objetivo do negócio e o contexto dos chamados, foram definidas 5 categorias de classificação de tickets:\n",
        "\n",
        "1. Rede\n",
        "Definição: Problemas relacionados à conectividade, infraestrutura de rede e acesso remoto.\n",
        "Exemplo: Internet instável, VPN, Wi-Fi...\n",
        "\n",
        "2. Computador (Hardware)\n",
        "Definição: Falhas físicas ou de desempenho em equipamentos.\n",
        "Exemplo: Notebook / desktop, Bateria, Tela...\n",
        "\n",
        "3. Software & Sistema Operacional\n",
        "Definição: Problemas em softwares instalados, IDEs, aplicações locais ou SO.\n",
        "Exemplo: Erro em aplicações, IDEs (IntelliJ, VS Code, etc.), Atualizações de sistema...\n",
        "\n",
        "4. Acesso, Permissões & Contas\n",
        "Definição: Problemas de autenticação, autorização ou privilégios.\n",
        "Exemplo: Login,Senha, Permissão negada, Acesso a sistemas...\n",
        "\n",
        "5. Outros\n",
        "Definição: Tudo que não se encaixa claramente nas categorias acima.\n",
        "\n",
        "\n",
        "Além disso, cada uma dessas categorias terão uma subcateorica de criticidade: Urgente e Normal."
      ],
      "metadata": {
        "id": "0dAayO462KBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline da solução**\n",
        "\n",
        "**1) Ingestão de dados (CSV)**\n",
        "   \n",
        "**2) Preparação e limpeza de texto**\n",
        "   - concatena subject + body\n",
        "   - normaliza (lowercase, remoção de ruído, etc.)\n",
        "   - gera clean_text\n",
        "   \n",
        "**3) Pré-rotulagem (weak labels) via dicionário**\n",
        "   - main_category {connectivity, computer_hardware, software_operating_system, access_permissions_accounts, other}\n",
        "   - criticality {urgent, normal}\n",
        "   ↓\n",
        "**4) Split global (hold-out único)**\n",
        "   - train/test estratificado por criticality\n",
        "   - preserva índices para coerência entre modelos\n",
        "   \n",
        "**5) Feature engineering (vetorização TF-IDF)**\n",
        "   - word n-grams (1–2)\n",
        "   - char n-grams (3–5)\n",
        "   - fit apenas no treino (evita data leakage)\n",
        "   - concatenação (hstack) - matriz final de features\n",
        "   ↓\n",
        "**6) Treinamento de modelos**\n",
        "   6.1) Criticidade (binário) – LinearSVC (dataset completo, inclui other)\n",
        "   6.2) Categoria (multiclasse) – LinearSVC (treino sem other; other = fallback)\n",
        "   ↓\n",
        "**7) Avaliação e validação**\n",
        "   - métricas no teste: accuracy, F1 macro, F1 urgent (criticidade)\n",
        "   - matriz de confusão e classification report\n",
        "   - diagnóstico de overfitting (train vs test)\n",
        "   - validação cruzada (CV) no treino\n",
        "   - interpretação: top features para o modelo de classes\n",
        "   \n",
        "**8) Predição em produção (função única)**\n",
        "   predict_ticket(text):\n",
        "     - aplica TF-IDF (transform)\n",
        "     - prevê criticality\n",
        "     - prevê main_category\n",
        "     - aplica fallback: se margin < threshold → other\n",
        "   \n",
        "**9) Saída estruturada**\n",
        "   { main_category, criticality, category_margin }\n"
      ],
      "metadata": {
        "id": "iw8KT-_oSmd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import de bases"
      ],
      "metadata": {
        "id": "x7zHD8Rf2Scf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Access to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "datapah = '/content/drive/MyDrive/casevoll/classificacao_atendimento.csv'\n",
        "\n",
        "# Load file in pandas and spark\n",
        "base = pd.read_csv(datapah)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C7pVBar2HOI",
        "outputId": "02fb6b81-4e68-4e73-ea4c-508537b32763"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6dIUMKth2Z2F",
        "outputId": "5a4a8f68-5ce8-449d-ab40-fcd539f97ca4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ticket_id                                            subject  \\\n",
              "0          2  Erro na Autocompletação de Código do IntelliJ ...   \n",
              "1         28  Problemas intermitentes de exibição após atual...   \n",
              "2         45  Pedido de Assistência para Administração de Se...   \n",
              "3         46                                                NaN   \n",
              "4         63  Urgente: Relato de Falha na Bateria do MacBook...   \n",
              "\n",
              "                                                body  \n",
              "0  Prezado Suporte ao Cliente <name>,\\n\\nEstou es...  \n",
              "1  Caro Suporte ao Cliente,\\n\\n Estou entrando em...  \n",
              "2  Prezado Suporte ao Cliente de Serviços de TI,\\...  \n",
              "3  Prezado <name>,\\n\\nSentimos muito ao saber sob...  \n",
              "4  Prezado Atendimento ao Cliente,<br><br>Recente...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e301e91-1167-4f54-a22e-b8c1347cfee8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticket_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Erro na Autocompletação de Código do IntelliJ ...</td>\n",
              "      <td>Prezado Suporte ao Cliente &lt;name&gt;,\\n\\nEstou es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>Problemas intermitentes de exibição após atual...</td>\n",
              "      <td>Caro Suporte ao Cliente,\\n\\n Estou entrando em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>Pedido de Assistência para Administração de Se...</td>\n",
              "      <td>Prezado Suporte ao Cliente de Serviços de TI,\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Prezado &lt;name&gt;,\\n\\nSentimos muito ao saber sob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>Urgente: Relato de Falha na Bateria do MacBook...</td>\n",
              "      <td>Prezado Atendimento ao Cliente,&lt;br&gt;&lt;br&gt;Recente...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e301e91-1167-4f54-a22e-b8c1347cfee8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e301e91-1167-4f54-a22e-b8c1347cfee8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e301e91-1167-4f54-a22e-b8c1347cfee8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "base",
              "summary": "{\n  \"name\": \"base\",\n  \"rows\": 473,\n  \"fields\": [\n    {\n      \"column\": \"ticket_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1193,\n        \"min\": 2,\n        \"max\": 3996,\n        \"num_unique_values\": 473,\n        \"samples\": [\n          506,\n          611,\n          293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 419,\n        \"samples\": [\n          \"Solicita\\u00e7\\u00e3o de Atualiza\\u00e7\\u00e3o de Servi\\u00e7o da AWS\",\n          \"Consulta sobre Planos de Pagamento para Dell XPS 13\",\n          \"Alta Prioridade: Falha no Servi\\u00e7o do Zoom\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 473,\n        \"samples\": [\n          \"Caro Suporte da Loja Online Tech,\\n\\nEstou enfrentando travamentos de papel frequentes com minha impressora Canon PIXMA MG3620, o que torna quase imposs\\u00edvel us\\u00e1-la de forma eficaz. Podemos arranjar uma troca para esta unidade? Meus detalhes de compra: N\\u00famero do Pedido <acc_num>, sob <name>. Por favor, me avise sobre os pr\\u00f3ximos passos. Obrigado pela sua ajuda.\\n\\nAtenciosamente,\\n\\n<name>\\n<tel_num>\",\n          \"Caro Time de Suporte de Servi\\u00e7os de TI,\\n\\nEstou entrando em contato para relatar um problema que estamos enfrentando com nosso Roteador Cisco ISR4331 na gest\\u00e3o das necessidades de rede empresarial. Nossa organiza\\u00e7\\u00e3o tem encontrado dificuldades significativas, pois o roteador parece incapaz de lidar com as demandas de alto desempenho necess\\u00e1rias para conex\\u00f5es seguras, que s\\u00e3o uma fun\\u00e7\\u00e3o essencial para nossas opera\\u00e7\\u00f5es.\\n\\nRecentemente, nossas necessidades de capacidade de rede aumentaram devido ao aumento do trabalho remoto, exigindo acesso seguro 24/7 para m\\u00faltiplos usu\\u00e1rios. Infelizmente, o roteador parece estar lutando nessas condi\\u00e7\\u00f5es, levando a interrup\\u00e7\\u00f5es frequentes e uma incapacidade de manter conex\\u00f5es confi\\u00e1veis e seguras. Essa degrada\\u00e7\\u00e3o de desempenho est\\u00e1 causando preocupa\\u00e7\\u00e3o consider\\u00e1vel, pois impacta severamente nossos processos e produtividade de neg\\u00f3cios.\\n\\nInicialmente, selecionamos o Roteador Cisco ISR4331 por suas especifica\\u00e7\\u00f5es robustas, que, no papel, pareciam mais do que adequadas para nossas necessidades. No entanto, na pr\\u00e1tica, est\\u00e1 provando ser inadequado para nossas demandas crescentes. Apesar de v\\u00e1rias tentativas de ajustes de configura\\u00e7\\u00e3o e uma atualiza\\u00e7\\u00e3o para o firmware mais recente, o problema persiste. Especulamos que as limita\\u00e7\\u00f5es atuais de hardware podem n\\u00e3o ser suficientes para nossas necessidades, mas apreciar\\u00edamos uma avalia\\u00e7\\u00e3o especializada de sua equipe para confirmar isso e aconselhar sobre poss\\u00edveis solu\\u00e7\\u00f5es.\\n\\nNosso objetivo \\u00e9 garantir conectividade robusta e de alta velocidade para nossas opera\\u00e7\\u00f5es internas e voltadas para o cliente, com as medidas de seguran\\u00e7a necess\\u00e1rias n\\u00e3o comprometidas. Por favor, reconhe\\u00e7a este pedido o mais r\\u00e1pido poss\\u00edvel e aconselhe sobre etapas ou oportunidades para suporte aprimorado, avalia\\u00e7\\u00e3o ou at\\u00e9 mesmo uma atualiza\\u00e7\\u00e3o para um modelo de roteador mais adequado, se considerado necess\\u00e1rio.\\n\\nObrigado pela sua aten\\u00e7\\u00e3o a este assunto urgente. Aguardo sua r\\u00e1pida resposta.\\n\\nAtenciosamente,\\n\\n<name>\\n<tel_num>\\n<acc_num>\",\n          \"Caro Suporte ao Cliente da Tech Online Store,\\n\\nEspero que esta mensagem o encontre bem. Estou entrando em contato para solicitar uma troca da minha impressora Canon PIXMA MG3620, comprada sob a conta <acc_num>. Desde a sua chegada recente, encontrei problemas de qualidade de impress\\u00e3o e problemas de conectividade espor\\u00e1dicos, que dificultaram significativamente minha experi\\u00eancia como usu\\u00e1rio. Agradeceria uma resolu\\u00e7\\u00e3o r\\u00e1pida para este assunto. Para mais detalhes, sinta-se \\u00e0 vontade para entrar em contato pelo meu n\\u00famero de telefone, <tel_num>.\\n\\nObrigado pela sua assist\\u00eancia.\\n\\nAtenciosamente,\\n\\n<name>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "zDyGCJzs2kIT",
        "outputId": "d9e193e1-dddd-4ffa-95c2-8221a6e62600"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ticket_id    473\n",
              "subject      419\n",
              "body         473\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ticket_id</th>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject</th>\n",
              "      <td>419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>body</th>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import bibliotecas\n",
        "\n",
        "\n",
        "# Standard library\n",
        "import re\n",
        "import html\n",
        "import unicodedata\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, Tuple\n",
        "\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import hstack\n",
        "\n"
      ],
      "metadata": {
        "id": "QU8iqyUkjvMF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploração e diagnóstico do dataset"
      ],
      "metadata": {
        "id": "l11Xgw_C3739"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#funções gerais\n",
        "\n",
        "@dataclass\n",
        "class ticket_dataset_quality_config:\n",
        "    subject_column_name: str = \"subject\"\n",
        "    body_column_name: str = \"body\"\n",
        "\n",
        "    # short/low-info thresholds\n",
        "    minimum_character_count: int = 60\n",
        "    minimum_word_count: int = 10\n",
        "\n",
        "    # generic messages / low-info patterns\n",
        "    generic_message_patterns: Tuple[str, ...] = (\n",
        "        r\"\\bpreciso de ajuda\\b\",\n",
        "        r\"\\bajuda\\b\",\n",
        "        r\"\\bn[aã]o funciona\\b\",\n",
        "        r\"\\bnao funciona\\b\",\n",
        "        r\"\\bcom problema\\b\",\n",
        "        r\"\\berro\\b\",\n",
        "        r\"\\bn[aã]o consigo\\b\",\n",
        "        r\"\\bnao consigo\\b\",\n",
        "        r\"\\burgente\\b\",  # used for criticidade signal\n",
        "    )\n",
        "\n",
        "    # near-duplicate computation cap\n",
        "    near_duplicate_sample_size: int = 2500\n",
        "    near_duplicate_similarity_threshold: float = 0.92\n",
        "    tfidf_max_features: int = 50000\n",
        "    tfidf_min_document_frequency: int = 2\n",
        "    tfidf_max_document_frequency: float = 0.95\n",
        "\n",
        "    # noise / thread / signature heuristics\n",
        "    maximum_lines_to_consider: int = 200\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Common functions\n",
        "# -----------------------------\n",
        "def normalize_text(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
        "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def count_words(text: str) -> int:\n",
        "    if not text:\n",
        "        return 0\n",
        "    return len(re.findall(r\"\\b\\w+\\b\", text, flags=re.UNICODE))\n",
        "\n",
        "\n",
        "def build_combined_text(base: pd.DataFrame, config: ticket_dataset_quality_config) -> pd.Series:\n",
        "    subject_series = base[config.subject_column_name].fillna(\"\").astype(str).str.strip()\n",
        "    body_series = base[config.body_column_name].fillna(\"\").astype(str).str.strip()\n",
        "    combined = (subject_series + \"\\n\\n\" + body_series).map(normalize_text)\n",
        "    return combined"
      ],
      "metadata": {
        "id": "cpVcEJLh3_OZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testando as funções acima\n",
        "\n",
        "raw_text_test_cases = [\n",
        "    None,\n",
        "    \"\",\n",
        "    \"   \",\n",
        "    \"Erro no sistema\",\n",
        "    \"Erro   grave    no   sistema\",\n",
        "    \"Falha\\r\\nna\\r\\naplicação\",\n",
        "    \"Sistema não abre\\rTela branca\",\n",
        "    \"Usuário relata erro ﬁ no login\",\n",
        "    \"ＡＢＣ falha crítica\",\n",
        "    \"Erro 404 detectado no módulo financeiro!!!\",\n",
        "    \"   Solicitação de suporte urgente   \",\n",
        "    \"\\n\\n\\nMuitas\\n\\n\\nlinhas\\n\\n\\n\",\n",
        "    \"Problema intermitente\\t\\tno\\t\\tservidor\",\n",
        "    \"ação rápida necessária\",\n",
        "]\n",
        "\n",
        "processed_text_results = []\n",
        "\n",
        "for raw_text in raw_text_test_cases:\n",
        "    normalized_text = normalize_text(raw_text)\n",
        "    word_count = count_words(normalized_text)\n",
        "\n",
        "    # Critério mínimo: texto normalizado não vazio e com pelo menos 2 palavras\n",
        "    if normalized_text and word_count >= 2:\n",
        "        processed_text_results.append({\n",
        "            \"original_text\": raw_text,\n",
        "            \"normalized_text\": normalized_text,\n",
        "            \"word_count\": word_count\n",
        "        })\n",
        "\n",
        "print(processed_text_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiFyxcfm37QX",
        "outputId": "8eb7c50d-be73-4273-a2e6-46dd878d674e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'original_text': 'Erro no sistema', 'normalized_text': 'Erro no sistema', 'word_count': 3}, {'original_text': 'Erro   grave    no   sistema', 'normalized_text': 'Erro grave no sistema', 'word_count': 4}, {'original_text': 'Falha\\r\\nna\\r\\naplicação', 'normalized_text': 'Falha\\nna\\naplicação', 'word_count': 3}, {'original_text': 'Sistema não abre\\rTela branca', 'normalized_text': 'Sistema não abre\\nTela branca', 'word_count': 5}, {'original_text': 'Usuário relata erro ﬁ no login', 'normalized_text': 'Usuário relata erro fi no login', 'word_count': 6}, {'original_text': 'ＡＢＣ falha crítica', 'normalized_text': 'ABC falha crítica', 'word_count': 3}, {'original_text': 'Erro 404 detectado no módulo financeiro!!!', 'normalized_text': 'Erro 404 detectado no módulo financeiro!!!', 'word_count': 6}, {'original_text': '   Solicitação de suporte urgente   ', 'normalized_text': 'Solicitação de suporte urgente', 'word_count': 4}, {'original_text': '\\n\\n\\nMuitas\\n\\n\\nlinhas\\n\\n\\n', 'normalized_text': 'Muitas\\n\\nlinhas', 'word_count': 2}, {'original_text': 'Problema intermitente\\t\\tno\\t\\tservidor', 'normalized_text': 'Problema intermitente no servidor', 'word_count': 4}, {'original_text': 'ação rápida necessária', 'normalized_text': 'ação rápida necessária', 'word_count': 3}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Verificação de campos vazios (assunto e corpo)\n",
        "\n",
        "def check_missing_ticket_fields(base: pd.DataFrame, config: ticket_dataset_quality_config) -> Dict[str, Any]:\n",
        "    subject_series = base[config.subject_column_name]\n",
        "    body_series = base[config.body_column_name]\n",
        "\n",
        "    is_subject_empty = subject_series.isna() | (subject_series.astype(str).str.strip() == \"\")\n",
        "    is_body_empty = body_series.isna() | (body_series.astype(str).str.strip() == \"\")\n",
        "    is_both_empty = is_subject_empty & is_body_empty\n",
        "\n",
        "    # \"subject empty but body filled\"\n",
        "    is_subject_empty_body_filled = is_subject_empty & (~is_body_empty)\n",
        "\n",
        "    # \"generic subject + short body\"\n",
        "    subject_text = subject_series.fillna(\"\").astype(str).str.lower().str.strip()\n",
        "    body_text = body_series.fillna(\"\").astype(str).map(normalize_text)\n",
        "    body_word_count = body_text.map(count_words)\n",
        "\n",
        "    generic_subject_patterns = (\n",
        "        r\"^ajuda$\",\n",
        "        r\"^suporte$\",\n",
        "        r\"^problema$\",\n",
        "        r\"^erro$\",\n",
        "        r\"^urgente$\",\n",
        "        r\"^d[uú]vida$\",\n",
        "        r\"^help$\",\n",
        "        r\"^issue$\",\n",
        "    )\n",
        "    is_generic_subject = subject_text.apply(\n",
        "        lambda s: any(re.search(p, s, flags=re.IGNORECASE) for p in generic_subject_patterns)\n",
        "    )\n",
        "    is_body_very_short = body_word_count < config.minimum_word_count\n",
        "    is_generic_subject_and_short_body = is_generic_subject & is_body_very_short & (~is_body_empty)\n",
        "\n",
        "    summary = {\n",
        "        \"subject_empty_row_count\": int(is_subject_empty.sum()),\n",
        "        \"body_empty_row_count\": int(is_body_empty.sum()),\n",
        "        \"both_empty_row_count\": int(is_both_empty.sum()),\n",
        "        \"subject_empty_body_filled_row_count\": int(is_subject_empty_body_filled.sum()),\n",
        "        \"generic_subject_and_short_body_row_count\": int(is_generic_subject_and_short_body.sum()),\n",
        "        \"subject_empty_ratio\": float(is_subject_empty.mean()),\n",
        "        \"body_empty_ratio\": float(is_body_empty.mean()),\n",
        "        \"both_empty_ratio\": float(is_both_empty.mean()),\n",
        "    }\n",
        "\n",
        "    masks = {\n",
        "        \"is_subject_empty\": is_subject_empty,\n",
        "        \"is_body_empty\": is_body_empty,\n",
        "        \"is_both_empty\": is_both_empty,\n",
        "        \"is_subject_empty_body_filled\": is_subject_empty_body_filled,\n",
        "        \"is_generic_subject_and_short_body\": is_generic_subject_and_short_body,\n",
        "    }\n",
        "\n",
        "    return {\"summary\": summary, \"masks\": masks}"
      ],
      "metadata": {
        "id": "znqSdUUH9xY5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 Conteúdo muito curto ou pouco informativo\n",
        "\n",
        "def check_low_information_tickets(\n",
        "    base: pd.DataFrame, combined_text: pd.Series, config: ticket_dataset_quality_config\n",
        ") -> Dict[str, Any]:\n",
        "    character_count = combined_text.map(len)\n",
        "    word_count = combined_text.map(count_words)\n",
        "\n",
        "    is_very_short = (character_count < config.minimum_character_count) | (word_count < config.minimum_word_count)\n",
        "\n",
        "    # Generic content indicator: matches generic phrases OR extremely low vocabulary diversity\n",
        "    def generic_hit(text: str) -> bool:\n",
        "        t = (text or \"\").lower()\n",
        "        return any(re.search(p, t, flags=re.IGNORECASE) for p in config.generic_message_patterns)\n",
        "\n",
        "    is_generic_message = combined_text.map(generic_hit)\n",
        "\n",
        "    # Heuristic: low distinct token ratio (signals vague content)\n",
        "    def distinct_token_ratio(text: str) -> float:\n",
        "        tokens = re.findall(r\"\\b\\w+\\b\", (text or \"\").lower(), flags=re.UNICODE)\n",
        "        if len(tokens) == 0:\n",
        "            return 0.0\n",
        "        return len(set(tokens)) / len(tokens)\n",
        "\n",
        "    distinct_ratio = combined_text.map(distinct_token_ratio)\n",
        "    is_low_distinct_ratio = distinct_ratio < 0.45  # heuristic threshold\n",
        "\n",
        "    is_low_information = is_very_short | (is_generic_message & is_low_distinct_ratio)\n",
        "\n",
        "    summary = {\n",
        "        \"very_short_row_count\": int(is_very_short.sum()),\n",
        "        \"very_short_ratio\": float(is_very_short.mean()),\n",
        "        \"generic_message_row_count\": int(is_generic_message.sum()),\n",
        "        \"low_distinct_ratio_row_count\": int(is_low_distinct_ratio.sum()),\n",
        "        \"low_information_row_count\": int(is_low_information.sum()),\n",
        "        \"low_information_ratio\": float(is_low_information.mean()),\n",
        "        \"thresholds\": {\n",
        "            \"minimum_character_count\": int(config.minimum_character_count),\n",
        "            \"minimum_word_count\": int(config.minimum_word_count),\n",
        "            \"low_distinct_ratio_threshold\": 0.45,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    artifacts = {\n",
        "        \"character_count\": character_count,\n",
        "        \"word_count\": word_count,\n",
        "        \"distinct_token_ratio\": distinct_ratio,\n",
        "    }\n",
        "\n",
        "    masks = {\n",
        "        \"is_very_short\": is_very_short,\n",
        "        \"is_generic_message\": is_generic_message,\n",
        "        \"is_low_distinct_ratio\": is_low_distinct_ratio,\n",
        "        \"is_low_information\": is_low_information,\n",
        "    }\n",
        "\n",
        "    return {\"summary\": summary, \"masks\": masks, \"artifacts\": artifacts}"
      ],
      "metadata": {
        "id": "7lC-3hEm-m_v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3 Duplicidade de tickets (exata e quase duplicada)\n",
        "\n",
        "def check_duplicate_tickets(combined_text: pd.Series, config: ticket_dataset_quality_config) -> Dict[str, Any]:\n",
        "    normalized = combined_text.fillna(\"\").astype(str).map(normalize_text)\n",
        "\n",
        "    is_exact_duplicate = normalized.duplicated(keep=False) & (normalized.str.len() > 0)\n",
        "    exact_duplicate_row_count = int(is_exact_duplicate.sum())\n",
        "    exact_duplicate_group_count = int(normalized[is_exact_duplicate].nunique())\n",
        "\n",
        "    # Near duplicates: TF-IDF cosine similarity (sample capped)\n",
        "    non_empty = normalized[normalized.str.len() > 0]\n",
        "    if non_empty.shape[0] < 10:\n",
        "        near_duplicate_summary = {\n",
        "            \"method\": \"tfidf_cosine_similarity\",\n",
        "            \"evaluated_row_count\": int(non_empty.shape[0]),\n",
        "            \"near_duplicate_pair_count\": 0,\n",
        "            \"near_duplicate_row_count\": 0,\n",
        "            \"note\": \"Not enough non-empty rows to evaluate near duplicates.\",\n",
        "        }\n",
        "    else:\n",
        "        if non_empty.shape[0] > config.near_duplicate_sample_size:\n",
        "            sampled = non_empty.sample(config.near_duplicate_sample_size, random_state=42)\n",
        "        else:\n",
        "            sampled = non_empty\n",
        "\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=config.tfidf_max_features,\n",
        "            min_df=config.tfidf_min_document_frequency,\n",
        "            max_df=config.tfidf_max_document_frequency,\n",
        "            ngram_range=(1, 2),\n",
        "        )\n",
        "        tfidf = vectorizer.fit_transform(sampled.tolist())\n",
        "        similarity = cosine_similarity(tfidf)\n",
        "\n",
        "        upper = np.triu_indices(similarity.shape[0], k=1)\n",
        "        similarities = similarity[upper]\n",
        "        near_duplicate_pair_count = int(np.sum(similarities >= config.near_duplicate_similarity_threshold))\n",
        "\n",
        "        adjacency = similarity >= config.near_duplicate_similarity_threshold\n",
        "        np.fill_diagonal(adjacency, False)\n",
        "        near_duplicate_row_count = int(np.sum(adjacency.any(axis=1)))\n",
        "\n",
        "        near_duplicate_summary = {\n",
        "            \"method\": \"tfidf_cosine_similarity\",\n",
        "            \"evaluated_row_count\": int(sampled.shape[0]),\n",
        "            \"near_duplicate_pair_count\": near_duplicate_pair_count,\n",
        "            \"near_duplicate_row_count\": near_duplicate_row_count,\n",
        "            \"similarity_threshold\": float(config.near_duplicate_similarity_threshold),\n",
        "            \"note\": \"Counts are based on a sample if dataset is large.\",\n",
        "        }\n",
        "\n",
        "    summary = {\n",
        "        \"exact_duplicate_row_count\": exact_duplicate_row_count,\n",
        "        \"exact_duplicate_group_count\": exact_duplicate_group_count,\n",
        "        \"near_duplicates\": near_duplicate_summary,\n",
        "    }\n",
        "\n",
        "    masks = {\n",
        "        \"is_exact_duplicate\": is_exact_duplicate,\n",
        "    }\n",
        "\n",
        "    return {\"summary\": summary, \"masks\": masks}"
      ],
      "metadata": {
        "id": "0za_gdQF-vi7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4 Presença de ruído textual (assinaturas, disclaimers e threads)\n",
        "\n",
        "def detect_text_noise_patterns(base: pd.DataFrame, combined_text: pd.Series, config: ticket_dataset_quality_config) -> Dict[str, Any]:\n",
        "    # Thread indicators\n",
        "    thread_line_patterns = [\n",
        "        r\"^\\s*de:\\s\", r\"^\\s*from:\\s\",\n",
        "        r\"^\\s*para:\\s\", r\"^\\s*to:\\s\",\n",
        "        r\"^\\s*assunto:\\s\", r\"^\\s*subject:\\s\",\n",
        "        r\"^\\s*enviado em:\\s\", r\"^\\s*sent:\\s\",\n",
        "        r\"^\\s*data:\\s\", r\"^\\s*date:\\s\",\n",
        "        r\"^\\s*cc:\\s\",\n",
        "        r\"^\\s*---+\\s*original message\\s*---+\",\n",
        "        r\"^\\s*---+\\s*mensagem original\\s*---+\",\n",
        "    ]\n",
        "\n",
        "    signature_patterns = [\n",
        "        r\"\\batenciosamente\\b\",\n",
        "        r\"\\batt\\.?\\b\",\n",
        "        r\"\\babra(ç|c)o(s)?\\b\",\n",
        "        r\"\\bobrigad[oa]\\b\",\n",
        "        r\"\\bsent from my (iphone|android)\\b\",\n",
        "        r\"\\benviado do meu (iphone|android)\\b\",\n",
        "        r\"\\bwhatsapp\\b\",\n",
        "        r\"\\btelefone\\b\",\n",
        "        r\"\\bcel(ular)?\\b\",\n",
        "    ]\n",
        "\n",
        "    disclaimer_patterns = [\n",
        "        r\"\\besta mensagem\\b.*\\bconfidencial\\b\",\n",
        "        r\"\\bconfidentiality\\b\",\n",
        "        r\"\\bse você recebeu esta mensagem por engano\\b\",\n",
        "        r\"\\bpor favor, apague\\b\",\n",
        "    ]\n",
        "\n",
        "    def extract_noise_flags(text: str) -> Dict[str, Any]:\n",
        "        text = text or \"\"\n",
        "        lines = text.split(\"\\n\")[: config.maximum_lines_to_consider]\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        thread_hits = 0\n",
        "        for line in lines:\n",
        "            line_lower = line.lower()\n",
        "            for p in thread_line_patterns:\n",
        "                if re.search(p, line_lower, flags=re.IGNORECASE):\n",
        "                    thread_hits += 1\n",
        "                    break\n",
        "\n",
        "        signature_hits = sum(len(re.findall(p, text_lower, flags=re.IGNORECASE)) for p in signature_patterns)\n",
        "        disclaimer_hits = sum(len(re.findall(p, text_lower, flags=re.IGNORECASE | re.DOTALL)) for p in disclaimer_patterns)\n",
        "\n",
        "        return {\n",
        "            \"thread_indicator_count\": int(thread_hits),\n",
        "            \"signature_indicator_count\": int(signature_hits),\n",
        "            \"disclaimer_indicator_count\": int(disclaimer_hits),\n",
        "            \"has_thread_markers\": bool(thread_hits >= 1),\n",
        "            \"has_signature_markers\": bool(signature_hits >= 2),\n",
        "            \"has_disclaimer_markers\": bool(disclaimer_hits >= 1),\n",
        "        }\n",
        "\n",
        "    noise_features_series = combined_text.map(extract_noise_flags)\n",
        "    noise_features_dataframe = pd.DataFrame(noise_features_series.tolist(), index=base.index)\n",
        "\n",
        "    summary = {\n",
        "        \"thread_markers_row_count\": int(noise_features_dataframe[\"has_thread_markers\"].sum()),\n",
        "        \"signature_markers_row_count\": int(noise_features_dataframe[\"has_signature_markers\"].sum()),\n",
        "        \"disclaimer_markers_row_count\": int(noise_features_dataframe[\"has_disclaimer_markers\"].sum()),\n",
        "        \"thread_markers_row_ratio\": float(noise_features_dataframe[\"has_thread_markers\"].mean()),\n",
        "        \"signature_markers_row_ratio\": float(noise_features_dataframe[\"has_signature_markers\"].mean()),\n",
        "        \"disclaimer_markers_row_ratio\": float(noise_features_dataframe[\"has_disclaimer_markers\"].mean()),\n",
        "    }\n",
        "\n",
        "    return {\"summary\": summary, \"noise_features_dataframe\": noise_features_dataframe}\n"
      ],
      "metadata": {
        "id": "11z4YqIb-4CE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5 Distribuição do tamanho do texto\n",
        "\n",
        "def compute_text_length_distribution(combined_text: pd.Series) -> Dict[str, Any]:\n",
        "    character_count = combined_text.fillna(\"\").astype(str).map(len)\n",
        "    word_count = combined_text.fillna(\"\").astype(str).map(count_words)\n",
        "\n",
        "    def describe_numeric(values: pd.Series) -> Dict[str, float]:\n",
        "        return {\n",
        "            \"count\": float(values.shape[0]),\n",
        "            \"mean\": float(values.mean()),\n",
        "            \"median\": float(values.median()),\n",
        "            \"p90\": float(values.quantile(0.90)),\n",
        "            \"p95\": float(values.quantile(0.95)),\n",
        "            \"p99\": float(values.quantile(0.99)),\n",
        "            \"max\": float(values.max()),\n",
        "            \"min\": float(values.min()),\n",
        "        }\n",
        "\n",
        "    summary = {\n",
        "        \"character_count_summary\": describe_numeric(character_count),\n",
        "        \"word_count_summary\": describe_numeric(word_count),\n",
        "    }\n",
        "\n",
        "    artifacts = {\"character_count\": character_count, \"word_count\": word_count}\n",
        "    return {\"summary\": summary, \"artifacts\": artifacts}\n",
        "\n"
      ],
      "metadata": {
        "id": "Lx_r5_Qd--sS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.6 Síntese da análise final do dataset\n",
        "# ============================================================\n",
        "def stage_3_6_build_dataset_xray(\n",
        "    base: pd.DataFrame,\n",
        "    combined_text: pd.Series,\n",
        "    results_3_1: Dict[str, Any],\n",
        "    results_3_2: Dict[str, Any],\n",
        "    results_3_3: Dict[str, Any],\n",
        "    results_3_4: Dict[str, Any],\n",
        "    results_3_5: Dict[str, Any],\n",
        ") -> Dict[str, Any]:\n",
        "    # Consolidate risk flags in one dataframe for inspection and downstream pipeline decisions.\n",
        "    noise_df = results_3_4[\"noise_features_dataframe\"]\n",
        "\n",
        "    risk_flags_dataframe = pd.DataFrame(index=base.index)\n",
        "    for key, mask in results_3_1[\"masks\"].items():\n",
        "        risk_flags_dataframe[key] = mask\n",
        "    for key, mask in results_3_2[\"masks\"].items():\n",
        "        risk_flags_dataframe[key] = mask\n",
        "    for key, mask in results_3_3[\"masks\"].items():\n",
        "        risk_flags_dataframe[key] = mask\n",
        "\n",
        "    risk_flags_dataframe = risk_flags_dataframe.join(noise_df)\n",
        "    risk_flags_dataframe[\"character_count\"] = results_3_5[\"artifacts\"][\"character_count\"]\n",
        "    risk_flags_dataframe[\"word_count\"] = results_3_5[\"artifacts\"][\"word_count\"]\n",
        "\n",
        "    # High risk definition: low info OR heavy noise OR duplicates OR both empty\n",
        "    is_high_risk_for_classification = (\n",
        "        risk_flags_dataframe[\"is_both_empty\"]\n",
        "        | risk_flags_dataframe[\"is_low_information\"]\n",
        "        | risk_flags_dataframe[\"is_exact_duplicate\"]\n",
        "        | risk_flags_dataframe[\"has_thread_markers\"]\n",
        "        | risk_flags_dataframe[\"has_disclaimer_markers\"]\n",
        "    )\n",
        "    risk_flags_dataframe[\"is_high_risk_for_classification\"] = is_high_risk_for_classification\n",
        "\n",
        "    xray_summary = {\n",
        "        \"dataset_shape\": {\"row_count\": int(base.shape[0]), \"column_count\": int(base.shape[1])},\n",
        "        \"high_risk_row_count\": int(is_high_risk_for_classification.sum()),\n",
        "        \"high_risk_ratio\": float(is_high_risk_for_classification.mean()),\n",
        "        \"stage_3_1_missing_fields\": results_3_1[\"summary\"],\n",
        "        \"stage_3_2_short_low_info\": results_3_2[\"summary\"],\n",
        "        \"stage_3_3_duplicates\": results_3_3[\"summary\"],\n",
        "        \"stage_3_4_noise\": results_3_4[\"summary\"],\n",
        "        \"stage_3_6_length_distribution\": results_3_5[\"summary\"],\n",
        "    }\n",
        "\n",
        "    return {\"summary\": xray_summary, \"risk_flags_dataframe\": risk_flags_dataframe}\n"
      ],
      "metadata": {
        "id": "QE3c7T9__Dn1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Orchestrator: runs all sub-steps of Stage 3\n",
        "\n",
        "\n",
        "def profile_ticket_dataset_quality(base: pd.DataFrame, config: Optional[ticket_dataset_quality_config] = None) -> Dict[str, Any]:\n",
        "    if config is None:\n",
        "        config = ticket_dataset_quality_config()\n",
        "\n",
        "    required_columns = {config.subject_column_name, config.body_column_name}\n",
        "    missing_columns = required_columns - set(base.columns)\n",
        "    if missing_columns:\n",
        "        raise ValueError(\n",
        "            f\"Missing required columns: {missing_columns}. \"\n",
        "            f\"Expected columns: {config.subject_column_name!r}, {config.body_column_name!r}.\"\n",
        "        )\n",
        "\n",
        "    combined_text = build_combined_text(base, config)\n",
        "\n",
        "    results_3_1 = check_missing_ticket_fields(base, config)\n",
        "    results_3_2 = check_low_information_tickets(base, combined_text, config)\n",
        "    results_3_3 = check_duplicate_tickets(combined_text, config)\n",
        "    results_3_4 = detect_text_noise_patterns(base, combined_text, config)\n",
        "    results_3_5 = compute_text_length_distribution(combined_text)\n",
        "    results_3_6 = stage_3_6_build_dataset_xray(\n",
        "        base=base,\n",
        "        combined_text=combined_text,\n",
        "        results_3_1=results_3_1,\n",
        "        results_3_2=results_3_2,\n",
        "        results_3_3=results_3_3,\n",
        "        results_3_4=results_3_4,\n",
        "        results_3_5=results_3_5\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"step_3_1\": results_3_1,\n",
        "        \"step_3_2\": results_3_2,\n",
        "        \"step_3_3\": results_3_3,\n",
        "        \"step_3_4\": results_3_4,\n",
        "        \"step_3_5\": results_3_5,\n",
        "        \"step_3_6\": results_3_6\n",
        "    }"
      ],
      "metadata": {
        "id": "8vUnFCCs_PLY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic unit tests\n",
        "\n",
        "\n",
        "def run_basic_unit_tests() -> None:\n",
        "    import pandas as pd\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer # Required for check_duplicate_tickets\n",
        "    from sklearn.metrics.pairwise import cosine_similarity # Required for check_duplicate_tickets\n",
        "    import numpy as np # Required for check_duplicate_tickets\n",
        "\n",
        "    sample_dataframe = pd.DataFrame(\n",
        "        {\n",
        "            'subject': ['', 'Pagamento pendente', '', 'Oi', 'Oi'], # Two empty subjects for assertion, and duplicates for combined_text\n",
        "            'body': ['Preciso de ajuda com reembolso', '', 'Preciso de ajuda com reembolso', 'ok', 'ok'], # One empty body for assertion, and duplicates for combined_text\n",
        "        }\n",
        "    )\n",
        "\n",
        "    test_config = ticket_dataset_quality_config(\n",
        "        subject_column_name='subject',\n",
        "        body_column_name='body',\n",
        "        minimum_character_count=10,\n",
        "        minimum_word_count=2,\n",
        "        near_duplicate_similarity_threshold=0.90\n",
        "    )\n",
        "\n",
        "    missing_report = check_missing_ticket_fields(sample_dataframe, test_config)\n",
        "    assert missing_report['summary']['subject_empty_row_count'] == 2  # '' and None\n",
        "    assert missing_report['summary']['body_empty_row_count'] == 1\n",
        "\n",
        "    combined_text = build_combined_text(sample_dataframe, test_config)\n",
        "    low_info_report = check_low_information_tickets(sample_dataframe, combined_text, test_config)\n",
        "    assert low_info_report['summary']['very_short_row_count'] >= 1\n",
        "\n",
        "    duplicate_report = check_duplicate_tickets(combined_text, test_config)\n",
        "    assert duplicate_report['summary']['exact_duplicate_row_count'] >= 1\n",
        "\n",
        "    noise_report = detect_text_noise_patterns(sample_dataframe, combined_text, test_config) # combined_text is now a required arg\n",
        "    # Updated assertion to reflect the 'summary' structure\n",
        "    assert 'signature_markers_row_count' in noise_report['summary']\n",
        "\n",
        "    length_report = compute_text_length_distribution(combined_text)\n",
        "    # Updated assertion to reflect the 'summary' structure\n",
        "    assert length_report['summary']['character_count_summary']['min'] <= length_report['summary']['character_count_summary']['max']\n",
        "\n",
        "\n",
        "run_basic_unit_tests()\n",
        "print('basic_unit_tests_passed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3BBu-ThAC3b",
        "outputId": "8329bff2-720e-4894-d39d-83922721f582"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basic_unit_tests_passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = profile_ticket_dataset_quality(base)"
      ],
      "metadata": {
        "id": "euM4VA2MAj4h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[\"step_3_1\"][\"summary\"])\n",
        "print(report[\"step_3_2\"][\"summary\"])\n",
        "print(report[\"step_3_3\"][\"summary\"])\n",
        "print(report[\"step_3_4\"][\"summary\"])\n",
        "print(report[\"step_3_5\"][\"summary\"])\n",
        "print(report[\"step_3_6\"][\"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg16TDCBAnX4",
        "outputId": "a1a77dcf-659f-4c4b-c112-85ef26af2095"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'subject_empty_row_count': 54, 'body_empty_row_count': 0, 'both_empty_row_count': 0, 'subject_empty_body_filled_row_count': 54, 'generic_subject_and_short_body_row_count': 0, 'subject_empty_ratio': 0.11416490486257928, 'body_empty_ratio': 0.0, 'both_empty_ratio': 0.0}\n",
            "{'very_short_row_count': 4, 'very_short_ratio': 0.008456659619450317, 'generic_message_row_count': 219, 'low_distinct_ratio_row_count': 0, 'low_information_row_count': 4, 'low_information_ratio': 0.008456659619450317, 'thresholds': {'minimum_character_count': 60, 'minimum_word_count': 10, 'low_distinct_ratio_threshold': 0.45}}\n",
            "{'exact_duplicate_row_count': 0, 'exact_duplicate_group_count': 0, 'near_duplicates': {'method': 'tfidf_cosine_similarity', 'evaluated_row_count': 473, 'near_duplicate_pair_count': 5, 'near_duplicate_row_count': 10, 'similarity_threshold': 0.92, 'note': 'Counts are based on a sample if dataset is large.'}}\n",
            "{'thread_markers_row_count': 0, 'signature_markers_row_count': 293, 'disclaimer_markers_row_count': 0, 'thread_markers_row_ratio': 0.0, 'signature_markers_row_ratio': 0.6194503171247357, 'disclaimer_markers_row_ratio': 0.0}\n",
            "{'character_count_summary': {'count': 473.0, 'mean': 834.4524312896406, 'median': 730.0, 'p90': 1465.8000000000002, 'p95': 1709.3999999999994, 'p99': 2224.3999999999996, 'max': 2796.0, 'min': 41.0}, 'word_count_summary': {'count': 473.0, 'mean': 122.09302325581395, 'median': 106.0, 'p90': 216.60000000000002, 'p95': 252.0, 'p99': 322.0, 'max': 397.0, 'min': 7.0}}\n",
            "{'dataset_shape': {'row_count': 473, 'column_count': 3}, 'high_risk_row_count': 4, 'high_risk_ratio': 0.008456659619450317, 'stage_3_1_missing_fields': {'subject_empty_row_count': 54, 'body_empty_row_count': 0, 'both_empty_row_count': 0, 'subject_empty_body_filled_row_count': 54, 'generic_subject_and_short_body_row_count': 0, 'subject_empty_ratio': 0.11416490486257928, 'body_empty_ratio': 0.0, 'both_empty_ratio': 0.0}, 'stage_3_2_short_low_info': {'very_short_row_count': 4, 'very_short_ratio': 0.008456659619450317, 'generic_message_row_count': 219, 'low_distinct_ratio_row_count': 0, 'low_information_row_count': 4, 'low_information_ratio': 0.008456659619450317, 'thresholds': {'minimum_character_count': 60, 'minimum_word_count': 10, 'low_distinct_ratio_threshold': 0.45}}, 'stage_3_3_duplicates': {'exact_duplicate_row_count': 0, 'exact_duplicate_group_count': 0, 'near_duplicates': {'method': 'tfidf_cosine_similarity', 'evaluated_row_count': 473, 'near_duplicate_pair_count': 5, 'near_duplicate_row_count': 10, 'similarity_threshold': 0.92, 'note': 'Counts are based on a sample if dataset is large.'}}, 'stage_3_4_noise': {'thread_markers_row_count': 0, 'signature_markers_row_count': 293, 'disclaimer_markers_row_count': 0, 'thread_markers_row_ratio': 0.0, 'signature_markers_row_ratio': 0.6194503171247357, 'disclaimer_markers_row_ratio': 0.0}, 'stage_3_6_length_distribution': {'character_count_summary': {'count': 473.0, 'mean': 834.4524312896406, 'median': 730.0, 'p90': 1465.8000000000002, 'p95': 1709.3999999999994, 'p99': 2224.3999999999996, 'max': 2796.0, 'min': 41.0}, 'word_count_summary': {'count': 473.0, 'mean': 122.09302325581395, 'median': 106.0, 'p90': 216.60000000000002, 'p95': 252.0, 'p99': 322.0, 'max': 397.0, 'min': 7.0}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusão da análise do dataset:**\n",
        "\n",
        "1 Campos vazios (assunto e corpo):\n",
        "subject_empty_row_count = 54 → 11,4% sem assunto\n",
        "body_empty_row_count = 0\n",
        "both_empty_row_count = 0\n",
        "\n",
        "O corpo do e-mail contém a informação principal.Não há perda total de informação em nenhum ticket.\n",
        "\n",
        "-Impacto no modelo: Baixo risco, desde que:assunto e corpo sejam unificados e\n",
        "templates e placeholders sejam removidos.\n",
        "\n",
        "Ação 1 : usar combined_text\n",
        "\n",
        "2 Conteúdo curto ou pouco informativo\n",
        "very_short_row_count = 0\n",
        "generic_message_row_count = 219 → 46,3%\n",
        "low_information_row_count = 0\n",
        "\n",
        "Não existem tickets “curtos demais”. Porém, quase metade contém linguagem genérica (“erro”, “problema”, “urgente”, etc.). Ou seja, pode ter conflito entre categorias e reduzir a confianã do modelo\n",
        "\n",
        "Ação 2: pré-processamento de ruído\n",
        "\n",
        "\n",
        "3 Duplicidade de tickets\n",
        "Duplicatas exatas: 0\n",
        "Near-duplicates:\n",
        "near_duplicate_pair_count = 5\n",
        "near_duplicate_row_count = 10\n",
        "\n",
        "Poucos tickets duplicados. Risco pontual de vazamento se esses pares caírem em treino e validação distintos.\n",
        "\n",
        "Ação 3: exclusão de pares quase idênticos do conjunto de validação\n",
        "\n",
        "\n",
        "4 Ruído textual (assinaturas, rodapés, threads)\n",
        "signature_markers_row_count = 293 → 61,9%\n",
        "thread_markers_row_count = 0\n",
        "disclaimer_markers_row_count = 0\n",
        "\n",
        "O principal ruído do dataset são assinaturas, fechamentos formais, texto institucional repetido\n",
        "\n",
        "Ação 4: emoção de assinaturas, placeholders, rodapés) - ponto crítico 62% contém esse ruído.\n",
        "\n",
        "6 Distribuição do tamanho do texto\n",
        "\n",
        "Mediana: 730 caracteres / 106 palavras\n",
        "p95: ~1700 caracteres / 252 palavras\n",
        "Máximo: 2796 caracteres / 397 palavras\n",
        "\n",
        "Dataset rico em conteúdo textual - sem problemas nesse quesito.\n",
        "\n",
        "**Conclusão geral:**\n",
        "\n",
        "A análise exploratória mostra que o dataset é adequado para classificação automática de tickets de TI, apresentando bom volume de informação textual e baixa duplicidade. Entretanto, são necessárias algumas ações para melhor desempenho do modelo.\n"
      ],
      "metadata": {
        "id": "S4iy16pyBKKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preparação do texto no dataset\n",
        "\n",
        "Exclusão dos \"erros\" textuais para menor impacto no modelo final"
      ],
      "metadata": {
        "id": "1OtI40tdC2fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatena assunto e corpo com um separador claro - ajuda o modelo porque o assunto frequentemente contém palavras-chave.\n",
        "\n",
        "subject_column_name = \"subject\"\n",
        "body_column_name = \"body\"\n",
        "\n",
        "base[\"combined_text\"] = (\n",
        "    base[subject_column_name].fillna(\"\").astype(str).str.strip()\n",
        "    + \"\\n\"\n",
        "    + base[body_column_name].fillna(\"\").astype(str).str.strip()\n",
        ").str.strip()\n"
      ],
      "metadata": {
        "id": "DuAXuFNVDIRo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## REMOÇÃO DE RUÍDOS NO DATASET - MELHORIA DA PERFORMANCE DO MODELO\n",
        "\n",
        "# 1 Remove formatação HTML\n",
        "def remove_html_formatting(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = html.unescape(text)\n",
        "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
        "    return text\n",
        "\n",
        "# 2 Remove links e e-mails\n",
        "def remove_links_and_email_addresses(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"http[s]?://\\S+|www\\.\\S+\", \" \", text)\n",
        "    text = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \" \", text)\n",
        "    return text\n",
        "\n",
        "# 3 Remove placeholders tipo <name>, <tel_num>\n",
        "def remove_placeholder_tokens(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"<\\s*[a-zA-Z_][a-zA-Z0-9_]*\\s*>\", \" \", text)\n",
        "    return text\n",
        "\n",
        "# 4 Remove threads de e-mail (mensagens anteriores)\n",
        "thread_marker_patterns = [\n",
        "    r\"(?im)^\\s*de:\\s\",\n",
        "    r\"(?im)^\\s*from:\\s\",\n",
        "    r\"(?im)^\\s*para:\\s\",\n",
        "    r\"(?im)^\\s*to:\\s\",\n",
        "    r\"(?im)^\\s*assunto:\\s\",\n",
        "    r\"(?im)^\\s*subject:\\s\",\n",
        "    r\"(?im)^\\s*enviado em:\\s\",\n",
        "    r\"(?im)^\\s*sent:\\s\",\n",
        "    r\"(?im)^\\s*data:\\s\",\n",
        "    r\"(?im)^\\s*---+\\s*mensagem original\\s*---+\"\n",
        "]\n",
        "\n",
        "def remove_email_threads(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "\n",
        "    earliest_cut_position = None\n",
        "    for pattern in thread_marker_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            earliest_cut_position = match.start() if earliest_cut_position is None else min(earliest_cut_position, match.start())\n",
        "\n",
        "    if earliest_cut_position is not None and earliest_cut_position > 0:\n",
        "        return text[:earliest_cut_position].strip()\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 5 Remove assinaturas, rodapés e disclaimers\n",
        "footer_marker_patterns = [\n",
        "    r\"(?im)^\\s*atenciosamente\\b\",\n",
        "    r\"(?im)^\\s*att\\.?\\b\",\n",
        "    r\"(?im)^\\s*abra(ç|c)o(s)?\\b\",\n",
        "    r\"(?im)^\\s*obrigad[oa]\\b\",\n",
        "    r\"(?im)^\\s*cordialmente\\b\",\n",
        "    r\"(?im)^\\s*enviado do meu (iphone|android)\\b\",\n",
        "    r\"(?im)\\besta mensagem\\b.*\\bconfidencial\\b\",\n",
        "    r\"(?im)\\bse você recebeu esta mensagem\\b\",\n",
        "]\n",
        "\n",
        "def remove_signatures_and_disclaimers(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "\n",
        "    earliest_cut_position = None\n",
        "    for pattern in footer_marker_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            earliest_cut_position = match.start() if earliest_cut_position is None else min(earliest_cut_position, match.start())\n",
        "\n",
        "    if earliest_cut_position is not None and earliest_cut_position > 0:\n",
        "        return text[:earliest_cut_position].strip()\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 6 Remove IDs irrelevantes\n",
        "def remove_irrelevant_identifiers(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(\n",
        "        r\"\\b[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\\b\",\n",
        "        \" \",\n",
        "        text,\n",
        "        flags=re.IGNORECASE,\n",
        "    )\n",
        "    text = re.sub(r\"\\b[a-zA-Z0-9]{25,}\\b\", \" \", text)\n",
        "    return text\n",
        "\n",
        "# 7 Normalização final\n",
        "def normalize_text_for_modeling(text: str) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"([!?\\.]){2,}\", r\"\\1\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "H-VTnrp4FwYH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY PIPELINE (dataset final pronto para usar)\n",
        "\n",
        "base[\"combined_text_without_html\"] = base[\"combined_text\"].map(remove_html_formatting)\n",
        "base[\"combined_text_without_links\"] = base[\"combined_text_without_html\"].map(remove_links_and_email_addresses)\n",
        "base[\"combined_text_without_placeholders\"] = base[\"combined_text_without_links\"].map(remove_placeholder_tokens)\n",
        "\n",
        "# Opcional mas recomendado:\n",
        "base[\"combined_text_without_threads\"] = base[\"combined_text_without_placeholders\"].map(remove_email_threads)\n",
        "\n",
        "\n",
        "base[\"combined_text_without_footer\"] = base[\"combined_text_without_threads\"].map(remove_signatures_and_disclaimers)\n",
        "base[\"combined_text_without_identifiers\"] = base[\"combined_text_without_footer\"].map(remove_irrelevant_identifiers)\n",
        "base[\"clean_text\"] = base[\"combined_text_without_identifiers\"].map(normalize_text_for_modeling)\n",
        "\n",
        "# Dataset final mínimo para modelagem\n",
        "final_dataset = base[[\"clean_text\"]].copy()"
      ],
      "metadata": {
        "id": "I-XfyYR8DUk8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "lfbc0ao0Diy_",
        "outputId": "ad3a4fbe-a9c0-4e56-d9a9-0502ad7fdcdc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text    473\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>clean_text</th>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WuOx2q14DkMN",
        "outputId": "0028affe-1ef8-4a77-f2fe-15b3b0aacb89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           clean_text\n",
              "0   erro na autocompletação de código do intellij ...\n",
              "1   problemas intermitentes de exibição após atual...\n",
              "2   pedido de assistência para administração de se...\n",
              "3   prezado , sentimos muito ao saber sobre o atra...\n",
              "4   urgente: relato de falha na bateria do macbook...\n",
              "5   assistência necessária para integração do jira...\n",
              "6   discrepância de faturamento no google workspac...\n",
              "7   urgente: problema de inatividade do serviço de...\n",
              "8   solicitação de soluções de gerenciamento da aw...\n",
              "9   interrupção do roteador cisco caro suporte ao ...\n",
              "10  urgente: problemas de conectividade de rede do...\n",
              "11  discrepância de cobrança no google workspace p...\n",
              "12  problemas de performance de rede com o roteado...\n",
              "13  solicitação de otimização das instâncias da aw...\n",
              "14  assistência imediata necessária para problemas...\n",
              "15  caro time de suporte ao cliente, espero que es...\n",
              "16  suporte urgente da aws necessário prezada equi...\n",
              "17  problema de piscar da tela no dell xps caro su...\n",
              "18  cobrança incorreta para o mysql 8.0.30 relato ...\n",
              "19  problema de conectividade wi-fi prezado equipe...\n",
              "20  buscando assistência imediata para problema de...\n",
              "21  solicitação de assistência com erro de instala...\n",
              "22  problema com a precisão da transação de softwa...\n",
              "23  assistência necessária para configuração sem f...\n",
              "24  consultoria para otimização de desempenho de s...\n",
              "25  atualização do fluxo de trabalho do jira caro(...\n",
              "26  cliente precisa de modo escuro e extensões par...\n",
              "27  assistência necessária: problema de configuraç...\n",
              "28  urgente: problema de acesso ao jira caro supor...\n",
              "29  consulta sobre o dell xps 13 prezado suporte a...\n",
              "30  suporte para resolução de problemas com atolam...\n",
              "31  problemas de conectividade com hp deskjet 3755...\n",
              "32  solicitação de devolução para compra do macboo...\n",
              "33  pedido de troca da canon pixma mg3620 caro sup...\n",
              "34  problemas de rede prezados serviços de ti, nos...\n",
              "35  prezado suporte ao cliente, estamos escrevendo...\n",
              "36  crítico: problemas com o sistema de bilhetagem...\n",
              "37  problemas técnicos com os recursos de vídeo e ...\n",
              "38  prezado suporte ao cliente, estamos escrevendo...\n",
              "39  pedido de troca: macbook air m1 com defeito ap...\n",
              "40  caro time de suporte da tech online store, esp...\n",
              "41  urgente: problema de conectividade do roteador...\n",
              "42  assistência necessária: problema de configuraç...\n",
              "43  discrepância de cobrança com o serviço aws car...\n",
              "44  problemas de conectividade com impressora cano...\n",
              "45  solicitação de assistência para dicas de otimi...\n",
              "46  problemas de conectividade e desempenho do wi-...\n",
              "47  solicitação de recurso de bug adicional no vsc...\n",
              "48  assistência imediata necessária: problemas de ...\n",
              "49  pedido de assistência para mudança de configur..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8ccd73f-d09f-48ca-ad6c-a9fc5a1bac7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>erro na autocompletação de código do intellij ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>problemas intermitentes de exibição após atual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pedido de assistência para administração de se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prezado , sentimos muito ao saber sobre o atra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>urgente: relato de falha na bateria do macbook...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>assistência necessária para integração do jira...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>discrepância de faturamento no google workspac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>urgente: problema de inatividade do serviço de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>solicitação de soluções de gerenciamento da aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>interrupção do roteador cisco caro suporte ao ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>urgente: problemas de conectividade de rede do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>discrepância de cobrança no google workspace p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>problemas de performance de rede com o roteado...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>solicitação de otimização das instâncias da aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>assistência imediata necessária para problemas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>caro time de suporte ao cliente, espero que es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>suporte urgente da aws necessário prezada equi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>problema de piscar da tela no dell xps caro su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>cobrança incorreta para o mysql 8.0.30 relato ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>problema de conectividade wi-fi prezado equipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>buscando assistência imediata para problema de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>solicitação de assistência com erro de instala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>problema com a precisão da transação de softwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>assistência necessária para configuração sem f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>consultoria para otimização de desempenho de s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>atualização do fluxo de trabalho do jira caro(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>cliente precisa de modo escuro e extensões par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>assistência necessária: problema de configuraç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>urgente: problema de acesso ao jira caro supor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>consulta sobre o dell xps 13 prezado suporte a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>suporte para resolução de problemas com atolam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>problemas de conectividade com hp deskjet 3755...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>solicitação de devolução para compra do macboo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>pedido de troca da canon pixma mg3620 caro sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>problemas de rede prezados serviços de ti, nos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>prezado suporte ao cliente, estamos escrevendo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>crítico: problemas com o sistema de bilhetagem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>problemas técnicos com os recursos de vídeo e ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>prezado suporte ao cliente, estamos escrevendo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>pedido de troca: macbook air m1 com defeito ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>caro time de suporte da tech online store, esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>urgente: problema de conectividade do roteador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>assistência necessária: problema de configuraç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>discrepância de cobrança com o serviço aws car...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>problemas de conectividade com impressora cano...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>solicitação de assistência para dicas de otimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>problemas de conectividade e desempenho do wi-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>solicitação de recurso de bug adicional no vsc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>assistência imediata necessária: problemas de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>pedido de assistência para mudança de configur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8ccd73f-d09f-48ca-ad6c-a9fc5a1bac7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8ccd73f-d09f-48ca-ad6c-a9fc5a1bac7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8ccd73f-d09f-48ca-ad6c-a9fc5a1bac7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_dataset",
              "summary": "{\n  \"name\": \"final_dataset\",\n  \"rows\": 473,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 473,\n        \"samples\": [\n          \"solicita\\u00e7\\u00e3o de troca de impressora caro suporte da loja online tech, estou enfrentando travamentos de papel frequentes com minha impressora canon pixma mg3620, o que torna quase imposs\\u00edvel us\\u00e1-la de forma eficaz. podemos arranjar uma troca para esta unidade? meus detalhes de compra: n\\u00famero do pedido , sob . por favor, me avise sobre os pr\\u00f3ximos passos. obrigado pela sua ajuda.\",\n          \"problema de rede empresarial caro time de suporte de servi\\u00e7os de ti, estou entrando em contato para relatar um problema que estamos enfrentando com nosso roteador cisco isr4331 na gest\\u00e3o das necessidades de rede empresarial. nossa organiza\\u00e7\\u00e3o tem encontrado dificuldades significativas, pois o roteador parece incapaz de lidar com as demandas de alto desempenho necess\\u00e1rias para conex\\u00f5es seguras, que s\\u00e3o uma fun\\u00e7\\u00e3o essencial para nossas opera\\u00e7\\u00f5es. recentemente, nossas necessidades de capacidade de rede aumentaram devido ao aumento do trabalho remoto, exigindo acesso seguro 24/7 para m\\u00faltiplos usu\\u00e1rios. infelizmente, o roteador parece estar lutando nessas condi\\u00e7\\u00f5es, levando a interrup\\u00e7\\u00f5es frequentes e uma incapacidade de manter conex\\u00f5es confi\\u00e1veis e seguras. essa degrada\\u00e7\\u00e3o de desempenho est\\u00e1 causando preocupa\\u00e7\\u00e3o consider\\u00e1vel, pois impacta severamente nossos processos e produtividade de neg\\u00f3cios. inicialmente, selecionamos o roteador cisco isr4331 por suas especifica\\u00e7\\u00f5es robustas, que, no papel, pareciam mais do que adequadas para nossas necessidades. no entanto, na pr\\u00e1tica, est\\u00e1 provando ser inadequado para nossas demandas crescentes. apesar de v\\u00e1rias tentativas de ajustes de configura\\u00e7\\u00e3o e uma atualiza\\u00e7\\u00e3o para o firmware mais recente, o problema persiste. especulamos que as limita\\u00e7\\u00f5es atuais de hardware podem n\\u00e3o ser suficientes para nossas necessidades, mas apreciar\\u00edamos uma avalia\\u00e7\\u00e3o especializada de sua equipe para confirmar isso e aconselhar sobre poss\\u00edveis solu\\u00e7\\u00f5es. nosso objetivo \\u00e9 garantir conectividade robusta e de alta velocidade para nossas opera\\u00e7\\u00f5es internas e voltadas para o cliente, com as medidas de seguran\\u00e7a necess\\u00e1rias n\\u00e3o comprometidas. por favor, reconhe\\u00e7a este pedido o mais r\\u00e1pido poss\\u00edvel e aconselhe sobre etapas ou oportunidades para suporte aprimorado, avalia\\u00e7\\u00e3o ou at\\u00e9 mesmo uma atualiza\\u00e7\\u00e3o para um modelo de roteador mais adequado, se considerado necess\\u00e1rio.\",\n          \"pedido de troca da canon pixma mg3620 caro suporte ao cliente da tech online store, espero que esta mensagem o encontre bem. estou entrando em contato para solicitar uma troca da minha impressora canon pixma mg3620, comprada sob a conta . desde a sua chegada recente, encontrei problemas de qualidade de impress\\u00e3o e problemas de conectividade espor\\u00e1dicos, que dificultaram significativamente minha experi\\u00eancia como usu\\u00e1rio. agradeceria uma resolu\\u00e7\\u00e3o r\\u00e1pida para este assunto. para mais detalhes, sinta-se \\u00e0 vontade para entrar em contato pelo meu n\\u00famero de telefone, .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_ticket_text_for_modeling(text: str) -> str:\n",
        "    text = remove_html_formatting(text)\n",
        "    text = remove_links_and_email_addresses(text)\n",
        "    text = remove_placeholder_tokens(text)\n",
        "    text = remove_email_threads(text)\n",
        "    text = remove_signatures_and_disclaimers(text)\n",
        "    text = remove_irrelevant_identifiers(text)\n",
        "    text = normalize_text_for_modeling(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Teste de integração\n",
        "test_texts = [\n",
        "    None,\n",
        "    \"<b>Erro</b> no sistema!!!\",\n",
        "    \"Acesse https://example.com para mais info\",\n",
        "    \"Olá <name>, preciso de ajuda\",\n",
        "    \"Mensagem atual\\n\\nDe: Fulano\\nAssunto: erro\",\n",
        "    \"Texto principal\\n\\nAtenciosamente,\\nEquipe\",\n",
        "    \"ID 123e4567-e89b-12d3-a456-426614174000 erro crítico!!!\",\n",
        "    \"   TEXTO   COM   MUITOS   ESPAÇOS!!!   \",\n",
        "]\n",
        "\n",
        "cleaned_results = [clean_ticket_text_for_modeling(raw_text) for raw_text in test_texts]\n",
        "\n",
        "for result in cleaned_results:\n",
        "    assert isinstance(result, str)\n",
        "    assert \"<\" not in result and \">\" not in result\n",
        "    assert \"http\" not in result and \"www.\" not in result\n",
        "    assert \"@\" not in result\n",
        "    assert \"  \" not in result\n",
        "    assert result == result.lower()\n",
        "    assert re.search(\n",
        "        r\"[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\",\n",
        "        result,\n",
        "        flags=re.IGNORECASE,\n",
        "    ) is None\n"
      ],
      "metadata": {
        "id": "D5aWdikCKHRv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(test_texts, cleaned_results))\n",
        "\n",
        "#funções validadas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFN63MMOINEz",
        "outputId": "7ada630c-f4d0-4fd8-a3ae-5366b8fd925e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, ''),\n",
              " ('<b>Erro</b> no sistema!!!', 'erro no sistema!'),\n",
              " ('Acesse https://example.com para mais info', 'acesse para mais info'),\n",
              " ('Olá <name>, preciso de ajuda', 'olá , preciso de ajuda'),\n",
              " ('Mensagem atual\\n\\nDe: Fulano\\nAssunto: erro', 'mensagem atual'),\n",
              " ('Texto principal\\n\\nAtenciosamente,\\nEquipe', 'texto principal'),\n",
              " ('ID 123e4567-e89b-12d3-a456-426614174000 erro crítico!!!',\n",
              "  'id erro crítico!'),\n",
              " ('   TEXTO   COM   MUITOS   ESPAÇOS!!!   ', 'texto com muitos espaços!')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "obs: As funções originalmente desenvolvidas no Item 3 tinham como objetivo realizar o diagnóstico de qualidade dos textos e identificar padrões de ruído, campos ausentes e problemas de consistência no dataset. No Item 4, essas funções foram refatoradas e parcialmente reescritas com foco em aplicação prática no pipeline de modelagem, priorizando reutilização, clareza semântica e eficiência operacional. A refatoração permitiu consolidar lógicas duplicadas, padronizar nomes e responsabilidades das funções, e transformar análises diagnósticas em etapas efetivas de tratamento e preparação dos dados, reduzindo ruídos que impactariam diretamente a performance do modelo."
      ],
      "metadata": {
        "id": "HhG5-PeUQJKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Construção do Modelo\n",
        "\n",
        "**Estrutura do problema**\n",
        "\n",
        "Cada ticket terá dois rótulos:\n",
        "main_category\n",
        "\n",
        "-connectivity\n",
        "-computer_hardware\n",
        "-software_operating_system\n",
        "-access_permissions_accounts\n",
        "-other\n",
        "\n",
        "criticality\n",
        "\n",
        "-urgent\n",
        "-normal"
      ],
      "metadata": {
        "id": "ipzICITOxEf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionários de palavras-chave para rotular os tickts\n",
        "\n",
        "CATEGORY_KEYWORDS = {\n",
        "    \"connectivity\": [\n",
        "        # conectividade\n",
        "        \"internet\", \"conexão\", \"conectividade\", \"rede\",\n",
        "        \"wifi\", \"wi-fi\", \"wireless\", \"lan\", \"wan\",\n",
        "\n",
        "        # acesso remoto\n",
        "        \"vpn\", \"acesso remoto\", \"remote access\",\n",
        "\n",
        "        # sintomas\n",
        "        \"instável\", \"queda de conexão\", \"sem internet\",\n",
        "        \"não conecta\", \"offline\", \"timeout\", \"latência\",\n",
        "        \"lento na rede\", \"sem sinal\",\n",
        "\n",
        "        # infraestrutura\n",
        "        \"proxy\", \"firewall\", \"dns\", \"ip\", \"gateway\",\n",
        "    ],\n",
        "\n",
        "    \"computer_hardware\": [\n",
        "        # dispositivos\n",
        "        \"notebook\", \"laptop\", \"desktop\", \"computador\",\n",
        "        \"pc\", \"máquina\", \"equipamento\",\n",
        "\n",
        "        # componentes\n",
        "        \"bateria\", \"carregador\", \"fonte\", \"tela\",\n",
        "        \"monitor\", \"teclado\", \"mouse\", \"touchpad\",\n",
        "        \"hd\", \"ssd\", \"memória\", \"ram\", \"processador\",\n",
        "\n",
        "        # sintomas físicos\n",
        "        \"não liga\", \"desligando sozinho\", \"superaquecendo\",\n",
        "        \"barulho\", \"aquecendo\", \"travando\",\n",
        "\n",
        "        # performance ligada a hardware\n",
        "        \"muito lento\", \"performance baixa\", \"hardware\",\n",
        "    ],\n",
        "\n",
        "    \"software_operating_system\": [\n",
        "        # sistemas operacionais\n",
        "        \"windows\", \"linux\", \"ubuntu\", \"mac\", \"macos\",\n",
        "\n",
        "        # aplicações genéricas\n",
        "        \"software\", \"aplicação\", \"programa\", \"sistema\",\n",
        "        \"app\", \"ferramenta\",\n",
        "\n",
        "        # IDEs e ferramentas comuns\n",
        "        \"vscode\", \"visual studio code\", \"intellij\",\n",
        "        \"pycharm\", \"eclipse\",\n",
        "\n",
        "        # erros e falhas\n",
        "        \"erro\", \"bug\", \"falha\", \"crash\",\n",
        "        \"não abre\", \"parou de funcionar\",\n",
        "\n",
        "        # atualizações\n",
        "        \"atualização\", \"update\", \"patch\",\n",
        "        \"versão incompatível\",\n",
        "    ],\n",
        "\n",
        "    \"access_permissions_accounts\": [\n",
        "        # autenticação\n",
        "        \"login\", \"logar\", \"senha\", \"credencial\",\n",
        "        \"autenticação\", \"autorização\",\n",
        "\n",
        "        # autorização\n",
        "        \"permissão\", \"permissão negada\", \"sem permissão\",\n",
        "        \"acesso negado\", \"não autorizado\",\n",
        "\n",
        "        # conta\n",
        "        \"conta\", \"usuário\", \"perfil\", \"role\",\n",
        "        \"bloqueado\", \"desbloqueio\",\n",
        "\n",
        "        # sistemas corporativos\n",
        "        \"single sign-on\", \"sso\", \"active directory\",\n",
        "        \"ldap\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "CRITICALITY_KEYWORDS = {\n",
        "    \"urgent\": [\n",
        "        \"urgente\", \"critico\", \"imediato\", \"bloqueado\", \"parado\",\n",
        "        \"não consigo trabalhar\", \"impacto crítico\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "FAyjJpaPQRWX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rotulagem baseada no dicionário\n",
        "\n",
        "def label_main_category(text: str) -> str:\n",
        "    text_lower = text.lower()\n",
        "    for category, keywords in CATEGORY_KEYWORDS.items():\n",
        "        if any(keyword in text_lower for keyword in keywords):\n",
        "            return category\n",
        "    return \"other\"\n",
        "\n",
        "\n",
        "def label_criticality(text: str) -> str:\n",
        "    text_lower = text.lower()\n",
        "    if any(keyword in text_lower for keyword in CRITICALITY_KEYWORDS[\"urgent\"]):\n",
        "        return \"urgent\"\n",
        "    return \"normal\"\n"
      ],
      "metadata": {
        "id": "NLi-L-iyyszE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicando a função de rotulagem inicial\n",
        "\n",
        "final_dataset[\"main_category\"] = final_dataset[\"clean_text\"].apply(label_main_category)\n",
        "final_dataset[\"criticality\"] = final_dataset[\"clean_text\"].apply(label_criticality)"
      ],
      "metadata": {
        "id": "lQ0-MvKB0LNb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IiVqzlBt3hcz",
        "outputId": "1a8ddc9b-6fa2-4161-d6ee-be53a58a99a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          clean_text  \\\n",
              "0  erro na autocompletação de código do intellij ...   \n",
              "1  problemas intermitentes de exibição após atual...   \n",
              "2  pedido de assistência para administração de se...   \n",
              "3  prezado , sentimos muito ao saber sobre o atra...   \n",
              "4  urgente: relato de falha na bateria do macbook...   \n",
              "\n",
              "               main_category criticality  \n",
              "0  software_operating_system      normal  \n",
              "1          computer_hardware      normal  \n",
              "2               connectivity      normal  \n",
              "3          computer_hardware      normal  \n",
              "4          computer_hardware      urgent  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdb5533b-b202-4cb2-bae6-af3ca387e54d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>main_category</th>\n",
              "      <th>criticality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>erro na autocompletação de código do intellij ...</td>\n",
              "      <td>software_operating_system</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>problemas intermitentes de exibição após atual...</td>\n",
              "      <td>computer_hardware</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pedido de assistência para administração de se...</td>\n",
              "      <td>connectivity</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prezado , sentimos muito ao saber sobre o atra...</td>\n",
              "      <td>computer_hardware</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>urgente: relato de falha na bateria do macbook...</td>\n",
              "      <td>computer_hardware</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdb5533b-b202-4cb2-bae6-af3ca387e54d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdb5533b-b202-4cb2-bae6-af3ca387e54d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdb5533b-b202-4cb2-bae6-af3ca387e54d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_dataset",
              "summary": "{\n  \"name\": \"final_dataset\",\n  \"rows\": 473,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 473,\n        \"samples\": [\n          \"solicita\\u00e7\\u00e3o de troca de impressora caro suporte da loja online tech, estou enfrentando travamentos de papel frequentes com minha impressora canon pixma mg3620, o que torna quase imposs\\u00edvel us\\u00e1-la de forma eficaz. podemos arranjar uma troca para esta unidade? meus detalhes de compra: n\\u00famero do pedido , sob . por favor, me avise sobre os pr\\u00f3ximos passos. obrigado pela sua ajuda.\",\n          \"problema de rede empresarial caro time de suporte de servi\\u00e7os de ti, estou entrando em contato para relatar um problema que estamos enfrentando com nosso roteador cisco isr4331 na gest\\u00e3o das necessidades de rede empresarial. nossa organiza\\u00e7\\u00e3o tem encontrado dificuldades significativas, pois o roteador parece incapaz de lidar com as demandas de alto desempenho necess\\u00e1rias para conex\\u00f5es seguras, que s\\u00e3o uma fun\\u00e7\\u00e3o essencial para nossas opera\\u00e7\\u00f5es. recentemente, nossas necessidades de capacidade de rede aumentaram devido ao aumento do trabalho remoto, exigindo acesso seguro 24/7 para m\\u00faltiplos usu\\u00e1rios. infelizmente, o roteador parece estar lutando nessas condi\\u00e7\\u00f5es, levando a interrup\\u00e7\\u00f5es frequentes e uma incapacidade de manter conex\\u00f5es confi\\u00e1veis e seguras. essa degrada\\u00e7\\u00e3o de desempenho est\\u00e1 causando preocupa\\u00e7\\u00e3o consider\\u00e1vel, pois impacta severamente nossos processos e produtividade de neg\\u00f3cios. inicialmente, selecionamos o roteador cisco isr4331 por suas especifica\\u00e7\\u00f5es robustas, que, no papel, pareciam mais do que adequadas para nossas necessidades. no entanto, na pr\\u00e1tica, est\\u00e1 provando ser inadequado para nossas demandas crescentes. apesar de v\\u00e1rias tentativas de ajustes de configura\\u00e7\\u00e3o e uma atualiza\\u00e7\\u00e3o para o firmware mais recente, o problema persiste. especulamos que as limita\\u00e7\\u00f5es atuais de hardware podem n\\u00e3o ser suficientes para nossas necessidades, mas apreciar\\u00edamos uma avalia\\u00e7\\u00e3o especializada de sua equipe para confirmar isso e aconselhar sobre poss\\u00edveis solu\\u00e7\\u00f5es. nosso objetivo \\u00e9 garantir conectividade robusta e de alta velocidade para nossas opera\\u00e7\\u00f5es internas e voltadas para o cliente, com as medidas de seguran\\u00e7a necess\\u00e1rias n\\u00e3o comprometidas. por favor, reconhe\\u00e7a este pedido o mais r\\u00e1pido poss\\u00edvel e aconselhe sobre etapas ou oportunidades para suporte aprimorado, avalia\\u00e7\\u00e3o ou at\\u00e9 mesmo uma atualiza\\u00e7\\u00e3o para um modelo de roteador mais adequado, se considerado necess\\u00e1rio.\",\n          \"pedido de troca da canon pixma mg3620 caro suporte ao cliente da tech online store, espero que esta mensagem o encontre bem. estou entrando em contato para solicitar uma troca da minha impressora canon pixma mg3620, comprada sob a conta . desde a sua chegada recente, encontrei problemas de qualidade de impress\\u00e3o e problemas de conectividade espor\\u00e1dicos, que dificultaram significativamente minha experi\\u00eancia como usu\\u00e1rio. agradeceria uma resolu\\u00e7\\u00e3o r\\u00e1pida para este assunto. para mais detalhes, sinta-se \\u00e0 vontade para entrar em contato pelo meu n\\u00famero de telefone, .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"main_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"computer_hardware\",\n          \"access_permissions_accounts\",\n          \"connectivity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"criticality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"urgent\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pré-rotulagem dos tickets foi realizada por meio de um dicionário de palavras-chave definido por categoria, mapeando termos e expressões recorrentes associados a problemas de rede, hardware, software/sistema operacional, acesso/permissões e uma classe de escape (outros), além de uma camada adicional de criticidade (urgent vs normal). Essa abordagem heurística permitiu gerar rótulos iniciais de forma automática e escalável, explorando padrões léxicos frequentes nos textos dos chamados e viabilizando a criação de um conjunto de treinamento inicial sem dependência imediata de rotulagem manual. Os rótulos gerados não são tratados como verdade absoluta, mas como weak labels, utilizados para bootstrap do modelo supervisionado, reduzindo esforço operacional e preparando o pipeline para refinamentos posteriores via validação humana, aprendizado semi-supervisionado e active learning."
      ],
      "metadata": {
        "id": "Bv62ZWG--R7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementação do modelo de classificação** - main class"
      ],
      "metadata": {
        "id": "HFU1xqHM-jnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT GLOBAL ÚNICO (dataset completo, inclui \"other\")\n",
        "# Estratificado por criticidade para garantir proporção urgent/normal\n",
        "# obs.: antes eu tinha feito um split para o modelo de classes e um para a criticidade, mas depois decidi unificar\n",
        "\n",
        "full_dataset = final_dataset.copy()\n",
        "\n",
        "X_text_full = full_dataset[\"clean_text\"].astype(str)\n",
        "y_criticality_full = full_dataset[\"criticality\"].astype(str)\n",
        "y_category_full = full_dataset[\"main_category\"].astype(str)\n",
        "\n",
        "X_train_full, X_test_full, y_criticality_train, y_criticality_test = train_test_split(\n",
        "    X_text_full,\n",
        "    y_criticality_full,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=y_criticality_full\n",
        ")\n",
        "\n",
        "print(f\"Global split | Train: {len(X_train_full)} | Test: {len(X_test_full)}\")\n",
        "print(\"Criticality distribution (train):\")\n",
        "print(y_criticality_train.value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr-emFN3I71K",
        "outputId": "d5bcc620-21f0-4f42-fe6c-9e0ba0fe7f39"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global split | Train: 378 | Test: 95\n",
            "Criticality distribution (train):\n",
            "criticality\n",
            "normal    0.693122\n",
            "urgent    0.306878\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VETORIZAÇÃO ÚNICA\n",
        "# Compartilhada por ambos os modelos: reduz inconsistência e evita vazamento\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=3,\n",
        "    max_df=0.90,\n",
        "    sublinear_tf=True,\n",
        "    norm=\"l2\",\n",
        ")\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"char_wb\",\n",
        "    ngram_range=(3, 5),\n",
        "    min_df=3,\n",
        "    max_df=0.90,\n",
        "    sublinear_tf=True,\n",
        "    norm=\"l2\",\n",
        ")\n",
        "\n",
        "X_train_word_full = word_vectorizer.fit_transform(X_train_full)\n",
        "X_test_word_full = word_vectorizer.transform(X_test_full)\n",
        "\n",
        "X_train_char_full = char_vectorizer.fit_transform(X_train_full)\n",
        "X_test_char_full = char_vectorizer.transform(X_test_full)\n",
        "\n",
        "X_train_full_final = hstack([X_train_word_full, X_train_char_full])\n",
        "X_test_full_final = hstack([X_test_word_full, X_test_char_full])\n"
      ],
      "metadata": {
        "id": "wERx9nScJHFa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os textos foram vetorizados por meio da técnica TF-IDF, combinando n-gramas de palavras (unigramas e bigramas) e n-gramas de caracteres, com o ajuste realizado exclusivamente sobre o conjunto de treinamento para evitar vazamento de dados. A aplicação de limites de frequência mínima e máxima (min_df e max_df) permitiu reduzir ruído e termos pouco informativos, enquanto os n-gramas de caracteres aumentaram a robustez do modelo a variações ortográficas, abreviações e erros de digitação comuns em tickets de suporte. Essa estratégia resultou em um espaço vetorial esparso, porém discriminativo, adequado para modelos lineares de alta dimensionalidade, favorecendo a separação semântica entre categorias e a generalização para textos não vistos."
      ],
      "metadata": {
        "id": "-guQr4cxLol8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Justificativa de escolha do modelo:**\n",
        "\n",
        "O modelo LinearSVC foi escolhido por sua adequação a problemas de classificação de texto em espaços TF-IDF de alta dimensionalidade e natureza esparsa, como é o caso de tickets de suporte. Por ser um classificador linear baseado em máxima margem, o LinearSVC é capaz de aprender fronteiras de decisão robustas mesmo na presença de classes desbalanceadas e rótulos ruidosos, apresentando desempenho consistente em termos de F1 macro quando comparado a alternativas como Random Forest ou modelos não lineares. Além disso, sua eficiência computacional e estabilidade em conjuntos com grande número de features o tornam uma escolha apropriada para cenários produtivos, nos quais se busca bom poder discriminativo, escalabilidade e interpretabilidade dos pesos associados aos termos mais relevantes para cada classe."
      ],
      "metadata": {
        "id": "78zX7wUPLy5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo de criticidade**"
      ],
      "metadata": {
        "id": "smshVYffJdFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO 1: CRITICIDADE (treina no dataset completo)\n",
        "#\n",
        "\n",
        "criticality_model = LinearSVC(class_weight=\"balanced\")\n",
        "criticality_model.fit(X_train_full_final, y_criticality_train)\n",
        "\n",
        "y_criticality_test_pred = criticality_model.predict(X_test_full_final)\n",
        "\n",
        "print(\"\\n[CRITICALITY] Test accuracy:\", accuracy_score(y_criticality_test, y_criticality_test_pred))\n",
        "print(\"[CRITICALITY] Test f1_macro:\", f1_score(y_criticality_test, y_criticality_test_pred, average=\"macro\"))\n",
        "print(\"[CRITICALITY] Test f1_urgent:\", f1_score(y_criticality_test, y_criticality_test_pred, pos_label=\"urgent\"))\n",
        "\n",
        "print(\"\\n[CRITICALITY] Classification report (test):\")\n",
        "print(classification_report(y_criticality_test, y_criticality_test_pred, digits=4))\n",
        "\n",
        "print(\"\\n[CRITICALITY] Confusion matrix (test) [urgent, normal]:\")\n",
        "print(confusion_matrix(y_criticality_test, y_criticality_test_pred, labels=[\"urgent\", \"normal\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ijGAWkI7xG",
        "outputId": "7157f70b-af98-49bf-e50a-2e7c7d9764ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CRITICALITY] Test accuracy: 0.9052631578947369\n",
            "[CRITICALITY] Test f1_macro: 0.8872180451127819\n",
            "[CRITICALITY] Test f1_urgent: 0.8421052631578947\n",
            "\n",
            "[CRITICALITY] Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal     0.9254    0.9394    0.9323        66\n",
            "      urgent     0.8571    0.8276    0.8421        29\n",
            "\n",
            "    accuracy                         0.9053        95\n",
            "   macro avg     0.8913    0.8835    0.8872        95\n",
            "weighted avg     0.9045    0.9053    0.9048        95\n",
            "\n",
            "\n",
            "[CRITICALITY] Confusion matrix (test) [urgent, normal]:\n",
            "[[24  5]\n",
            " [ 4 62]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting check (criticality)\n",
        "y_criticality_train_pred = criticality_model.predict(X_train_full_final)\n",
        "\n",
        "train_accuracy = accuracy_score(y_criticality_train, y_criticality_train_pred)\n",
        "test_accuracy = accuracy_score(y_criticality_test, y_criticality_test_pred)\n",
        "\n",
        "train_f1_macro = f1_score(y_criticality_train, y_criticality_train_pred, average=\"macro\")\n",
        "test_f1_macro = f1_score(y_criticality_test, y_criticality_test_pred, average=\"macro\")\n",
        "\n",
        "train_f1_urgent = f1_score(y_criticality_train, y_criticality_train_pred, pos_label=\"urgent\")\n",
        "test_f1_urgent = f1_score(y_criticality_test, y_criticality_test_pred, pos_label=\"urgent\")\n",
        "\n",
        "print(\"\\n[CRITICALITY] Overfitting check:\")\n",
        "print(f\"Train accuracy: {train_accuracy:.4f} | Test accuracy: {test_accuracy:.4f} | Gap: {(train_accuracy - test_accuracy):.4f}\")\n",
        "print(f\"Train f1_macro: {train_f1_macro:.4f} | Test f1_macro: {test_f1_macro:.4f} | Gap: {(train_f1_macro - test_f1_macro):.4f}\")\n",
        "print(f\"Train f1_urgent: {train_f1_urgent:.4f} | Test f1_urgent: {test_f1_urgent:.4f} | Gap: {(train_f1_urgent - test_f1_urgent):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NQTQ2jLI7q9",
        "outputId": "1c59e7b5-32ac-4a47-fee6-3047434a9305"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CRITICALITY] Overfitting check:\n",
            "Train accuracy: 1.0000 | Test accuracy: 0.9053 | Gap: 0.0947\n",
            "Train f1_macro: 1.0000 | Test f1_macro: 0.8872 | Gap: 0.1128\n",
            "Train f1_urgent: 1.0000 | Test f1_urgent: 0.8421 | Gap: 0.1579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation (criticality) no treino global\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_accuracy_scores = []\n",
        "cv_f1_macro_scores = []\n",
        "cv_f1_urgent_scores = []\n",
        "\n",
        "y_train_for_cv = y_criticality_train.reset_index(drop=True)\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train_full_final, y_train_for_cv):\n",
        "    X_tr = X_train_full_final[train_idx]\n",
        "    X_val = X_train_full_final[val_idx]\n",
        "    y_tr = y_train_for_cv.iloc[train_idx]\n",
        "    y_val = y_train_for_cv.iloc[val_idx]\n",
        "\n",
        "    fold_model = LinearSVC(class_weight=\"balanced\")\n",
        "    fold_model.fit(X_tr, y_tr)\n",
        "\n",
        "    y_val_pred = fold_model.predict(X_val)\n",
        "\n",
        "    cv_accuracy_scores.append(accuracy_score(y_val, y_val_pred))\n",
        "    cv_f1_macro_scores.append(f1_score(y_val, y_val_pred, average=\"macro\"))\n",
        "    cv_f1_urgent_scores.append(f1_score(y_val, y_val_pred, pos_label=\"urgent\"))\n",
        "\n",
        "print(\"\\n[CRITICALITY] CV results:\")\n",
        "print(\"CV accuracy mean:\", float(np.mean(cv_accuracy_scores)), \"std:\", float(np.std(cv_accuracy_scores)))\n",
        "print(\"CV f1_macro mean:\", float(np.mean(cv_f1_macro_scores)), \"std:\", float(np.std(cv_f1_macro_scores)))\n",
        "print(\"CV f1_urgent mean:\", float(np.mean(cv_f1_urgent_scores)), \"std:\", float(np.std(cv_f1_urgent_scores)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjMMxa9QI7mt",
        "outputId": "1fc581ad-d77a-4df2-93ae-4e79f7a24b1e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CRITICALITY] CV results:\n",
            "CV accuracy mean: 0.9152280701754387 std: 0.03739228296700755\n",
            "CV f1_macro mean: 0.8978178903712205 std: 0.045400273827998404\n",
            "CV f1_urgent mean: 0.8557175058708953 std: 0.06459021127676923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação do modelo: **\n",
        "\n",
        "O modelo de criticidade, conforme esperado, apresentou desempenho elevado e consistente no conjunto de teste, com acurácia de aproximadamente 90,5% e F1 macro de 0,89, indicando boa capacidade de discriminação entre chamados urgent e normal, mesmo diante do desbalanceamento natural entre as classes.\n",
        "\n",
        "O F1 da classe urgente (≈ 0,84) demonstra que o modelo identifica de forma eficaz a maioria dos tickets críticos, mantendo bom equilíbrio entre precisão (≈ 0,86) e recall (≈ 0,83), o que é essencial para minimizar o risco operacional de falsos negativos e a boa identificação de tickets urgentes.\n",
        "\n",
        "A matriz de confusão confirma esse comportamento, com a maior parte dos chamados urgentes corretamente classificados e um número limitado de erros, predominantemente confundindo urgentes com normais.\n",
        "\n",
        "A análise de overfitting mostra gaps moderados entre treino e teste — esperados em modelos lineares treinados sobre representações TF-IDF de alta dimensionalidade — sem evidência de alto overfitting. Essa conclusão é reforçada pelos resultados de validação cruzada, cujas médias (CV F1 macro ≈ 0,90 e CV F1 urgent ≈ 0,86) são consistentes com o desempenho no teste e apresentam desvios padrão relativamente baixos, indicando estabilidade, boa generalização e robustez do modelo para uso em produção.\n"
      ],
      "metadata": {
        "id": "pMPCX1qVJwWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo de classes**"
      ],
      "metadata": {
        "id": "Kxa26d58JyrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO 2: CATEGORIA (treina SEM 'other' e mantém o split global)\n",
        "#\n",
        "train_indices = X_train_full.index\n",
        "test_indices = X_test_full.index\n",
        "\n",
        "train_category_mask = (y_category_full.loc[train_indices] != \"other\")\n",
        "test_category_mask = (y_category_full.loc[test_indices] != \"other\")\n",
        "\n",
        "train_category_indices = train_indices[train_category_mask]\n",
        "test_category_indices = test_indices[test_category_mask]\n",
        "\n",
        "y_category_train = y_category_full.loc[train_category_indices]\n",
        "y_category_test = y_category_full.loc[test_category_indices]\n",
        "\n",
        "# mapear índices -> posições na matriz esparsa (posicional)\n",
        "train_pos_map = pd.Series(np.arange(len(train_indices)), index=train_indices)\n",
        "test_pos_map = pd.Series(np.arange(len(test_indices)), index=test_indices)\n",
        "\n",
        "train_positions = train_pos_map.loc[train_category_indices].to_numpy()\n",
        "test_positions = test_pos_map.loc[test_category_indices].to_numpy()\n",
        "\n",
        "X_train_category_final = X_train_full_final[train_positions]\n",
        "X_test_category_final = X_test_full_final[test_positions]\n",
        "\n",
        "print(\"\\n[CATEGORY] Derived split from global split:\")\n",
        "print(f\"Train category: {X_train_category_final.shape[0]} | Test category: {X_test_category_final.shape[0]}\")\n",
        "print(\"Category distribution (train):\")\n",
        "print(y_category_train.value_counts(normalize=True))\n",
        "\n",
        "\n",
        "category_model = LinearSVC(class_weight=\"balanced\")\n",
        "category_model.fit(X_train_category_final, y_category_train)\n",
        "\n",
        "y_category_test_pred = category_model.predict(X_test_category_final)\n",
        "\n",
        "print(\"\\n[CATEGORY] Test accuracy:\", accuracy_score(y_category_test, y_category_test_pred))\n",
        "print(\"[CATEGORY] Test f1_macro:\", f1_score(y_category_test, y_category_test_pred, average=\"macro\"))\n",
        "\n",
        "print(\"\\n[CATEGORY] Classification report (test):\")\n",
        "print(classification_report(y_category_test, y_category_test_pred, digits=4))\n",
        "\n",
        "print(\"\\n[CATEGORY] Confusion matrix (test):\")\n",
        "print(confusion_matrix(y_category_test, y_category_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF6QK75oI7io",
        "outputId": "613c8333-9d97-4e82-caec-a747ba8c2511"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CATEGORY] Derived split from global split:\n",
            "Train category: 367 | Test category: 91\n",
            "Category distribution (train):\n",
            "main_category\n",
            "connectivity                   0.547684\n",
            "computer_hardware              0.217984\n",
            "software_operating_system      0.128065\n",
            "access_permissions_accounts    0.106267\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "[CATEGORY] Test accuracy: 0.7582417582417582\n",
            "[CATEGORY] Test f1_macro: 0.6062097902097902\n",
            "\n",
            "[CATEGORY] Classification report (test):\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "access_permissions_accounts     0.7500    0.4286    0.5455         7\n",
            "          computer_hardware     0.6154    0.6154    0.6154        13\n",
            "               connectivity     0.8182    0.9153    0.8640        59\n",
            "  software_operating_system     0.5000    0.3333    0.4000        12\n",
            "\n",
            "                   accuracy                         0.7582        91\n",
            "                  macro avg     0.6709    0.5731    0.6062        91\n",
            "               weighted avg     0.7420    0.7582    0.7428        91\n",
            "\n",
            "\n",
            "[CATEGORY] Confusion matrix (test):\n",
            "[[ 3  0  4  0]\n",
            " [ 1  8  2  2]\n",
            " [ 0  3 54  2]\n",
            " [ 0  2  6  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting check (classe)\n",
        "y_category_train_pred = category_model.predict(X_train_category_final)\n",
        "\n",
        "train_accuracy = accuracy_score(y_category_train, y_category_train_pred)\n",
        "test_accuracy = accuracy_score(y_category_test, y_category_test_pred)\n",
        "\n",
        "train_f1_macro = f1_score(y_category_train, y_category_train_pred, average=\"macro\")\n",
        "test_f1_macro = f1_score(y_category_test, y_category_test_pred, average=\"macro\")\n",
        "\n",
        "print(\"\\n[CATEGORY] Overfitting check:\")\n",
        "print(f\"Train accuracy: {train_accuracy:.4f} | Test accuracy: {test_accuracy:.4f} | Gap: {(train_accuracy - test_accuracy):.4f}\")\n",
        "print(f\"Train f1_macro: {train_f1_macro:.4f} | Test f1_macro: {test_f1_macro:.4f} | Gap: {(train_f1_macro - test_f1_macro):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QpQpjWgJ1v8",
        "outputId": "c9346520-b58b-4c21-b774-3fe578490a63"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CATEGORY] Overfitting check:\n",
            "Train accuracy: 1.0000 | Test accuracy: 0.7582 | Gap: 0.2418\n",
            "Train f1_macro: 1.0000 | Test f1_macro: 0.6062 | Gap: 0.3938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Cross-validation (category) no treino de categoria\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_accuracy_scores = []\n",
        "cv_f1_macro_scores = []\n",
        "\n",
        "y_category_train_for_cv = y_category_train.reset_index(drop=True)\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train_category_final, y_category_train_for_cv):\n",
        "    X_tr = X_train_category_final[train_idx]\n",
        "    X_val = X_train_category_final[val_idx]\n",
        "    y_tr = y_category_train_for_cv.iloc[train_idx]\n",
        "    y_val = y_category_train_for_cv.iloc[val_idx]\n",
        "\n",
        "    fold_model = LinearSVC(class_weight=\"balanced\")\n",
        "    fold_model.fit(X_tr, y_tr)\n",
        "\n",
        "    y_val_pred = fold_model.predict(X_val)\n",
        "\n",
        "    cv_accuracy_scores.append(accuracy_score(y_val, y_val_pred))\n",
        "    cv_f1_macro_scores.append(f1_score(y_val, y_val_pred, average=\"macro\"))\n",
        "\n",
        "print(\"\\n[CATEGORY] CV results:\")\n",
        "print(\"CV accuracy mean:\", float(np.mean(cv_accuracy_scores)), \"std:\", float(np.std(cv_accuracy_scores)))\n",
        "print(\"CV f1_macro mean:\", float(np.mean(cv_f1_macro_scores)), \"std:\", float(np.std(cv_f1_macro_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AvKLBpMJ1Ym",
        "outputId": "97f61ef1-8ac5-447a-8058-0ea065800604"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CATEGORY] CV results:\n",
            "CV accuracy mean: 0.7167345427619399 std: 0.03173233717022916\n",
            "CV f1_macro mean: 0.5765130671544116 std: 0.05365732328932599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação do modelo de classes**\n",
        "\n",
        "O modelo de classificação de categorias apresentou desempenho sólido no conjunto de teste, com acurácia de aproximadamente 75,8% e F1 macro de 0,61, refletindo uma capacidade consistente de discriminação entre as quatro classes principais, mesmo diante de um cenário claramente desbalanceado.\n",
        "\n",
        "A classe nconnectivity representa mais de 54% dos exemplos de treino.O bom desempenho dessa classe é evidenciado por alto recall (≈ 0,92) e F1-score elevado (≈ 0,86), indicando que o modelo identifica corretamente a maioria dos tickets relacionados à rede.\n",
        "\n",
        "As classes computer_hardware e access_permissions_accounts apresentaram desempenho intermediário, com precisão e recall moderados, enquanto software_operating_system mostrou maior dificuldade, especialmente em recall, refletindo a sobreposição semântica com outras categorias e o menor volume de exemplos disponíveis.\n",
        "\n",
        "A matriz de confusão confirma que os principais erros decorrem da confusão entre software_operating_system, computer_hardware e connectivity, um padrão esperado em textos de suporte técnico.\n",
        "\n",
        "A análise de overfitting revela um gap elevado entre treino e teste — comum em modelos lineares treinados sobre representações TF-IDF de alta dimensionalidade e rótulos fracos — porém a validação cruzada apresenta métricas médias (CV F1 macro ≈ 0,58) próximas às obtidas no teste, com baixo desvio padrão, indicando estabilidade e boa capacidade de generalização dentro das limitações impostas pelo volume e qualidade dos dados.\n",
        "\n"
      ],
      "metadata": {
        "id": "X31M1xNnKLtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importância das variáveis\n",
        "\n",
        "\n",
        "def get_feature_names_with_prefix(word_vectorizer, char_vectorizer):\n",
        "    \"\"\"\n",
        "    Builds a unified feature name list matching the hstack([word_tfidf, char_tfidf]) order.\n",
        "    Adds prefixes so you can distinguish word vs char features.\n",
        "    \"\"\"\n",
        "    word_feature_names = word_vectorizer.get_feature_names_out()\n",
        "    char_feature_names = char_vectorizer.get_feature_names_out()\n",
        "\n",
        "    word_feature_names = np.array([f\"word::{name}\" for name in word_feature_names], dtype=object)\n",
        "    char_feature_names = np.array([f\"char::{name}\" for name in char_feature_names], dtype=object)\n",
        "\n",
        "    all_feature_names = np.concatenate([word_feature_names, char_feature_names])\n",
        "    return all_feature_names\n",
        "\n",
        "\n",
        "def print_top_features_per_class(linear_svc_model, feature_names, top_n=20):\n",
        "    \"\"\"\n",
        "    Prints the top_n features with the highest positive weights for each class.\n",
        "    For multiclass LinearSVC (one-vs-rest), coef_ has shape [n_classes, n_features].\n",
        "    \"\"\"\n",
        "    class_labels = linear_svc_model.classes_\n",
        "    coef_matrix = linear_svc_model.coef_  # shape: (n_classes, n_features)\n",
        "\n",
        "    for class_index, class_label in enumerate(class_labels):\n",
        "        class_coef = coef_matrix[class_index]\n",
        "\n",
        "        # Top positive weights (features most indicative of this class)\n",
        "        top_indices = np.argsort(class_coef)[-top_n:][::-1]\n",
        "        top_features = feature_names[top_indices]\n",
        "        top_weights = class_coef[top_indices]\n",
        "\n",
        "        print(f\"\\nTop {top_n} features for class '{class_label}':\")\n",
        "        for feat, w in zip(top_features, top_weights):\n",
        "            print(f\"  {feat:<40} {w:>10.4f}\")\n",
        "\n",
        "\n",
        "# Build feature names aligned with your hstack order\n",
        "all_feature_names = get_feature_names_with_prefix(word_vectorizer, char_vectorizer)\n",
        "\n",
        "# Print per-class top features\n",
        "print_top_features_per_class(category_model, all_feature_names, top_n=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uFpl2AcLMuf",
        "outputId": "bbdaa85d-ef79-4976-9999-b87037e6e665"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 features for class 'access_permissions_accounts':\n",
            "  word::administração do                       0.4460\n",
            "  word::troca para                             0.4351\n",
            "  word::de papel                               0.4253\n",
            "  word::papel                                  0.4194\n",
            "  word::de administração                       0.4163\n",
            "  word::administração                          0.4092\n",
            "  word::detectado                              0.4024\n",
            "  word::de cobrança                            0.3895\n",
            "  word::compra                                 0.3852\n",
            "  word::da aws                                 0.3690\n",
            "  word::atolamentos                            0.3599\n",
            "  word::atolamentos de                         0.3599\n",
            "  word::sob                                    0.3510\n",
            "  word::cobrança                               0.3440\n",
            "  word::parece                                 0.3436\n",
            "  word::serviços em                            0.3414\n",
            "  word::unidade                                0.3333\n",
            "  word::aws caro                               0.3287\n",
            "  word::serviço afetando                       0.3276\n",
            "  word::do slack                               0.3197\n",
            "\n",
            "Top 20 features for class 'computer_hardware':\n",
            "  word::tela                                   0.9933\n",
            "  word::de faturamento                         0.7615\n",
            "  word::faturamento                            0.7007\n",
            "  word::bateria                                0.6650\n",
            "  char::ram                                    0.5879\n",
            "  word::teclado                                0.4731\n",
            "  char::rame                                   0.4500\n",
            "  char::ramen                                  0.4500\n",
            "  char:: tela                                  0.4389\n",
            "  char::tela                                   0.4389\n",
            "  word::um erro                                0.4248\n",
            "  char::tela                                   0.4199\n",
            "  word::de tela                                0.3973\n",
            "  word::com defeito                            0.3785\n",
            "  word::atualização                            0.3775\n",
            "  word::várias                                 0.3551\n",
            "  word::ou substituição                        0.3525\n",
            "  word::termos                                 0.3497\n",
            "  word::respeito                               0.3463\n",
            "  char::urame                                  0.3462\n",
            "\n",
            "Top 20 features for class 'connectivity':\n",
            "  word::equipe                                 1.2218\n",
            "  word::equipe de                              0.7876\n",
            "  word::rede                                   0.6996\n",
            "  word::nossa equipe                           0.5885\n",
            "  char::pla                                    0.5527\n",
            "  word::conectividade                          0.5514\n",
            "  char::ipe                                    0.5413\n",
            "  word::implantação                            0.5279\n",
            "  char::quip                                   0.5255\n",
            "  char:: equ                                   0.5255\n",
            "  char:: eq                                    0.5255\n",
            "  char:: equi                                  0.5255\n",
            "  char::uip                                    0.5255\n",
            "  char::equip                                  0.5255\n",
            "  char::quipe                                  0.5243\n",
            "  char::uipe                                   0.5243\n",
            "  char::lan                                    0.5221\n",
            "  char::plan                                   0.5193\n",
            "  char::equi                                   0.4812\n",
            "  char::qui                                    0.4660\n",
            "\n",
            "Top 20 features for class 'software_operating_system':\n",
            "  word::aconselhamento                         0.5019\n",
            "  word::problema com                           0.4956\n",
            "  word::instalação                             0.4497\n",
            "  word::com adobe                              0.4177\n",
            "  word::no jira                                0.4136\n",
            "  word::disponibilidade do                     0.3997\n",
            "  word::sobre disponibilidade                  0.3799\n",
            "  word::pagamento                              0.3687\n",
            "  word::nosso sistema                          0.3677\n",
            "  word::do sistema                             0.3661\n",
            "  word::resolver esse                          0.3656\n",
            "  word::sua assistência                        0.3509\n",
            "  word::recurso de                             0.3492\n",
            "  word::melhorar                               0.3429\n",
            "  word::habilitar                              0.3359\n",
            "  word::11                                     0.3346\n",
            "  word::que essas                              0.3294\n",
            "  word::para problemas                         0.3238\n",
            "  word::do office                              0.3235\n",
            "  word::ajudem resolver                        0.3165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A análise dos coeficientes do modelo LinearSVC evidencia que o classificador aprendeu padrões léxicos semanticamente coerentes com cada categoria, reforçando a interpretabilidade da solução.\n",
        "\n",
        "Para access_permissions_accounts, destacam-se termos relacionados a administração, cobrança, serviços em nuvem e permissões de sistemas corporativos (por exemplo, administração, AWS, cobrança, Slack), indicando que o modelo capturou corretamente o vocabulário típico de solicitações envolvendo acesso, gestão e autorizações.\n",
        "\n",
        "Na classe computer_hardware, as features mais relevantes estão fortemente associadas a componentes físicos (tela, bateria, teclado, RAM), além de n-gramas de caracteres que aumentam a robustez a variações ortográficas, confirmando uma separação clara baseada em falhas ou limitações de equipamentos.\n",
        "\n",
        "A classe connectivity apresenta pesos elevados para termos ligados a rede, conectividade e infraestrutura (rede, conectividade, LAN, equipe), com destaque para n-gramas de caracteres que capturam variações linguísticas comuns nesses relatos.\n",
        "\n",
        "Por fim, em software_operating_system, predominam expressões associadas a instalação, problemas em aplicações e sistemas corporativos (instalação, sistema, Adobe, Office, Jira), refletindo adequadamente tickets relacionados a falhas ou configurações de software.\n",
        "\n",
        "De forma geral, a distribuição das features confirma que a combinação de TF-IDF (palavras e caracteres) com um modelo linear permitiu aprender sinais discriminativos consistentes com o domínio do problema, validando tanto a qualidade dos dados quanto a adequação da abordagem adotada."
      ],
      "metadata": {
        "id": "2TJ7f1cDQUb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Predição de novos tickets"
      ],
      "metadata": {
        "id": "lQ0E1zgVKOWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predição de novos tickets\n",
        "\n",
        "def predict_ticket(text: str, category_margin_threshold: float = 0.20) -> dict:\n",
        "    text_series = pd.Series([str(text)])\n",
        "\n",
        "    word_features = word_vectorizer.transform(text_series)\n",
        "    char_features = char_vectorizer.transform(text_series)\n",
        "    combined_features = hstack([word_features, char_features])\n",
        "\n",
        "    predicted_criticality = str(criticality_model.predict(combined_features)[0])\n",
        "\n",
        "    category_scores = category_model.decision_function(combined_features)\n",
        "    best_margin = float(np.max(category_scores))\n",
        "    predicted_category = str(category_model.predict(combined_features)[0])\n",
        "\n",
        "    if best_margin < category_margin_threshold:\n",
        "        predicted_category = \"other\"\n",
        "\n",
        "    return {\n",
        "        \"main_category\": predicted_category,\n",
        "        \"criticality\": predicted_criticality,\n",
        "        \"category_margin\": round(best_margin, 4)\n",
        "    }\n",
        "\n",
        "print(predict_ticket(\"não consigo acessar a vpn e estou bloqueado, urgente\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuV_RHVrKPVL",
        "outputId": "9a340d0a-2425-4224-f025-6afa5e801c10"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'main_category': 'other', 'criticality': 'urgent', 'category_margin': -0.0357}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exemplo 1\n",
        "\n",
        "# Exemplo 1 — Ticket de rede com alta criticidade\n",
        "ticket_1 = (\n",
        "    \"Não consigo acessar a VPN desde esta manhã, a conexão cai o tempo todo \"\n",
        "    \"e estou completamente bloqueado para trabalhar. Preciso de ajuda urgente.\"\n",
        ")\n",
        "\n",
        "print(\"Example 1 prediction:\")\n",
        "print(predict_ticket(ticket_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxHITN0KdkX",
        "outputId": "5d0a032d-b60c-4a31-f895-e9399c1fecb7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 prediction:\n",
            "{'main_category': 'other', 'criticality': 'urgent', 'category_margin': 0.1249}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exemplo 2\n",
        "\n",
        "# Exemplo 2 — Ticket ambíguo / baixa confiança (fallback para 'other')\n",
        "ticket_2 = (\n",
        "    \"Olá, gostaria de uma orientação sobre um procedimento interno que \"\n",
        "    \"não encontrei na documentação e não sei qual sistema utilizar.\"\n",
        ")\n",
        "\n",
        "print(\"\\nExample 2 prediction:\")\n",
        "print(predict_ticket(ticket_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBwn33FUKO3o",
        "outputId": "6b11db5c-670a-4815-fefe-a880496e5b7b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 2 prediction:\n",
            "{'main_category': 'other', 'criticality': 'normal', 'category_margin': -0.1752}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Resposta as perguntas"
      ],
      "metadata": {
        "id": "Be1TKtqERh3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Já que as classes foram definidas por você, como você avaliaria a classificação feita em novos\n",
        "tickets?**\n",
        "\n",
        "Como as classes iniciais foram definidas por mim via weak supervision (dicionário + regras), eu trataria a avaliação de novos tickets como um processo em duas camadas: primeiro, validaria a consistência interna do modelo com o esquema de classes (o que mede “aderência ao rótulo fraco”); em seguida, estabeleceria um mecanismo contínuo de validação com ground truth humano para medir a performance “real” do negócio.\n",
        "\n",
        "Na prática, eu criaria um gold set incremental (amostragem recorrente de tickets recentes) priorizando casos de maior risco e maior incerteza: tickets com baixa margem (category_margin próxima ao limiar), tickets preditos como other, amostras das classes minoritárias (ex.: access_permissions_accounts e software_operating_system), e casos em que regras e modelo divergirem.\n",
        "\n",
        "A métrica principal para categoria seria F1 macro (evita mascarar erro sob desbalanceamento), e para criticidade eu privilegiaria recall e F1 de urgent, porque o custo de falso negativo (classificar urgente como normal) tende a ser operacionalmente mais alto.\n",
        "\n",
        "Também avaliaria a performance por faixas de confiança (ex.: F1 para margin > 0,2 / 0,4 / 0,6), pois isso permite transformar “confiança” em decisão de produto, ajustando o fallback other para maximizar segurança e cobertura.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eq6OJwjZVlke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Como você iria monitorar essa solução? Que métricas você iria monitorar?**\n",
        "\n",
        "Para monitorar a solução em produção, eu separaria o monitoramento em métricas de comportamento do modelo, qualidade do dado e impacto operacional, porque problemas diferentes se manifestam em camadas distintas.\n",
        "\n",
        "No comportamento do modelo, monitoraria continuamente a distribuição das classes preditas (detecção de mudanças abruptas), a taxa de fallback para other (principal indicador de incerteza e drift), e a distribuição da margem do SVM (queda de p50/p95 de margem é um sinal precoce de drift semântico). Para criticidade, eu trataria recall de urgent como SLO quando houver feedback humano ou auditoria, e acompanharia a taxa de discordância entre urgência prevista e urgência corrigida por agentes.\n",
        "\n",
        "Em qualidade de dado, eu acompanharia drift de texto (mudança de vocabulário, n-grams, comprimento médio, proporção de textos muito curtos, presença de templates e assinaturas), além de integridade (campos vazios, duplicatas e spikes de ruído).\n",
        "\n",
        "Em impacto operacional, as métricas mais relevantes seriam taxa de reclassificação manual, tempo até primeira resposta e SLA por criticidade, assertividade de roteamento por equipe (quando a categoria alimenta filas), e efeitos em backlog (redução de retrabalho e redistribuição).\n",
        "\n",
        "Com esses sinais, eu implementaria alertas simples: aumento sustentado de other, queda de margem média, mudança abrupta no mix de classes e aumento de correção manual — cada alerta com runbook de diagnóstico e ações (ex.: ajuste de dicionário, revisão de threshold, coleta de rótulos).\n",
        "\n"
      ],
      "metadata": {
        "id": "nEYFoz8qYFUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Haveria retreino? Qual seria a estratégia para rodar o treino novamente? Qual periodicidade?**\n",
        "\n",
        "Sim, haveria retreino, porque tickets mudam com o tempo (novos sistemas, novas políticas, mudanças de vocabulário e processos) e isso gera data drift e concept drift.\n",
        "\n",
        "Eu adotaria uma estratégia híbrida: um retreino periódico mínimo (tipicamente mensal no início, podendo virar bimestral/trimestral se o ambiente for estável) e um retreino por gatilho, acionado quando métricas de drift e qualidade indicarem degradação (aumento de other, queda de margens, aumento de reclassificação manual, mudança de distribuição de classes, piora de recall em urgent).\n",
        "\n",
        "O retreino usaria uma janela deslizante (por exemplo, últimos 3–6 meses) para capturar linguagem atual, com um buffer histórico para preservar padrões de classes raras, e manteria um conjunto fixo de validação para garantir comparabilidade entre versões. Do ponto de vista de MLOps, eu versionaria explicitamente: modelo, vetorizadores TF-IDF, threshold de fallback e métricas offline/online por versão, com rollout controlado e critério de rollback baseado em métricas de produção."
      ],
      "metadata": {
        "id": "S9tfKzKaYTha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. (Bônus) Se decidíssemos rotular 1% desses dados agora, como você mudaria sua abordagem para um aprendizado semi-supervisionado ou active learning?**\n",
        "\n",
        "Se decidirmos rotular 1% dos dados agora (imaginei que fosse de forma manual), eu mudaria a abordagem para maximizar retorno por rótulo, combinando active learning + semi-supervisionado.\n",
        "\n",
        "Em vez de rotular 1% aleatoriamente (que tende a concentrar em redes e não melhora as classes difíceis), eu selecionaria amostras informativas: baixa margem (incerteza), tickets em other, divergências entre regra e modelo, e amostras que cubram diversidade semântica (clusterização para evitar redundância).\n",
        "\n",
        "Esse 1% se torna um gold set de alta qualidade, que eu usaria para\n",
        "\n",
        "(i) recalibrar/ajustar thresholds\n",
        "\n",
        "(ii) treinar um modelo supervisionado mais fiel ao negócio, priorizando F1 macro e recall de urgent.\n",
        "\n",
        "Em paralelo, eu aplicaria self-training: o modelo treinado no gold set pseudo-rotula o restante com um filtro de alta confiança (margem alta), e eu re-treinaria ponderando exemplos humanos com peso maior e pseudo-rótulos com peso menor, reduzindo a influência do ruído do weak labeling.\n",
        "\n",
        "Essa estratégia melhora especialmente as classes minoritárias e reduz confusões semânticas, além de diminuir a dependência do dicionário ao longo do tempo, mantendo other como mecanismo de segurança para casos realmente ambíguos ou fora de escopo."
      ],
      "metadata": {
        "id": "TYqrHhkiYcKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Perspectivas futuras\n",
        "\n"
      ],
      "metadata": {
        "id": "UdZe-QDig7Eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em uma abordagem mais sofisticada, especialmente em cenários com maior volume de dados ou maior variabilidade semântica, o dicionário inicial de palavras-chave poderia ser substituído — ou complementado — por uma LLM atuando como rotulador.\n",
        "\n",
        "Nesse desenho, a LLM seria utilizada para gerar rótulos iniciais de categoria e criticidade a partir de prompts estruturados, contendo definições claras das classes, exemplos positivos e negativos e regras explícitas de decisão, garantindo maior cobertura semântica do que listas estáticas de palavras. Essa estratégia reduz o viés léxico do dicionário, captura melhor sinônimos, contexto e intenções implícitas do texto e se adapta mais rapidamente a novos sistemas, jargões ou mudanças organizacionais.\n",
        "Para mitigar ruído, os rótulos produzidos pela LLM poderiam ser acompanhados de um score de confiança, permitindo filtrar apenas predições de alta confiabilidade ou combinar múltiplas chamadas (self-consistency).\n",
        "\n",
        "Em seguida, esses rótulos serviriam como base para treinar um modelo supervisionado mais simples e eficiente (como o LinearSVC), preservando custo e latência em produção. Como evolução adicional, a LLM também poderia ser integrada ao ciclo de active learning, sendo acionada apenas para tickets com baixa confiança do modelo tradicional, funcionando como um “especialista sob demanda” e maximizando ganho de informação com controle de custo computacional."
      ],
      "metadata": {
        "id": "b7ItOHdOhAYP"
      }
    }
  ]
}